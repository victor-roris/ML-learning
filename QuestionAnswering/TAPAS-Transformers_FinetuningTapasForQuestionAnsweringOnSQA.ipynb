{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TAPAS-Transformers_FinetuningTapasForQuestionAnsweringOnSQA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d1c74530dc6430189b8e57591d98e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d18f63c05579474b9ccbdbb83d18d3e7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_00060e719684477d831f33d1985839e5",
              "IPY_MODEL_7cb58557540d4246a2aef673bc6a22c7"
            ]
          }
        },
        "d18f63c05579474b9ccbdbb83d18d3e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "00060e719684477d831f33d1985839e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c266b536b0c14e6e863dd2e829166b01",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 262028,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 262028,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c6c727318fe43109e91d74d3ab64a65"
          }
        },
        "7cb58557540d4246a2aef673bc6a22c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3d66c996c582463e87dbdbdabb4f5bb8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 262k/262k [00:04&lt;00:00, 62.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a15d57b702742a5a3331b5d42466404"
          }
        },
        "c266b536b0c14e6e863dd2e829166b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c6c727318fe43109e91d74d3ab64a65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d66c996c582463e87dbdbdabb4f5bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a15d57b702742a5a3331b5d42466404": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5152a8b555045e3812c7b773c9efaec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c426ac608dda407d836f1add28538aa5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_816d4f80aaa74d4d8bb21252ea01703b",
              "IPY_MODEL_3ef7007065684238982ed1d77b76febf"
            ]
          }
        },
        "c426ac608dda407d836f1add28538aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "816d4f80aaa74d4d8bb21252ea01703b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_83b191ff25b243f9be12bd64c25292b1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 154,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 154,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ae39050afce404392b9be61c0c2a801"
          }
        },
        "3ef7007065684238982ed1d77b76febf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_29115da651044e068722783bcc8ebc87",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 154/154 [00:00&lt;00:00, 284B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_43b3d1819c4446a3923043ae66f9cd7e"
          }
        },
        "83b191ff25b243f9be12bd64c25292b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ae39050afce404392b9be61c0c2a801": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29115da651044e068722783bcc8ebc87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "43b3d1819c4446a3923043ae66f9cd7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e9b93a0035d4157a4b327c6571597ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_38db1eafdd724b3f8f5bcde8841e67d8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_82f2196a08aa421fb30643504dbec5e5",
              "IPY_MODEL_fa4df53ff99442639c1bef27cba544e3"
            ]
          }
        },
        "38db1eafdd724b3f8f5bcde8841e67d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "82f2196a08aa421fb30643504dbec5e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4863cb7777e84b4fb96fec70f09f0f02",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 490,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 490,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd644514150447a5a51b699c143599f5"
          }
        },
        "fa4df53ff99442639c1bef27cba544e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e4bd0a48e7ca4596bf2ecf53f7e177c0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 490/490 [00:00&lt;00:00, 781B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46ec528ecb2b4d87afd207b9f9adaf2d"
          }
        },
        "4863cb7777e84b4fb96fec70f09f0f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd644514150447a5a51b699c143599f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4bd0a48e7ca4596bf2ecf53f7e177c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46ec528ecb2b4d87afd207b9f9adaf2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86d91ed4d5f44e44abaed861f84c828c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_29599a3d9a764f7d88e615bdedf1b9a9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1b22ffcc38094db0ba1ea78a95dea8a7",
              "IPY_MODEL_9e8ad7e417734b5f98834c9bad0b2b32"
            ]
          }
        },
        "29599a3d9a764f7d88e615bdedf1b9a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b22ffcc38094db0ba1ea78a95dea8a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9ada6a69004a4b6d8d91d538fde2ec22",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1432,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1432,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_29b306a71ef24fddb802a2e8997c57f5"
          }
        },
        "9e8ad7e417734b5f98834c9bad0b2b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_62f0caf4fdf5411b87d25c2e7688c97a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.43k/1.43k [00:02&lt;00:00, 601B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9cdba32b44bd4a1e91392f51f249b7fa"
          }
        },
        "9ada6a69004a4b6d8d91d538fde2ec22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "29b306a71ef24fddb802a2e8997c57f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62f0caf4fdf5411b87d25c2e7688c97a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9cdba32b44bd4a1e91392f51f249b7fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45cfb9e907e04e3285f245ad12b39d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d581abebc1a145889984194e1cdc8ec3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c4963ef28d4f44bc98e7e13cd1d28173",
              "IPY_MODEL_21e29565491c41a4b704bf9e33a19543"
            ]
          }
        },
        "d581abebc1a145889984194e1cdc8ec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4963ef28d4f44bc98e7e13cd1d28173": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_72401569fa2846c8bb541c8cec5b3601",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442768791,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442768791,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6494bf53b28b4fedb70e188ba8e8ffef"
          }
        },
        "21e29565491c41a4b704bf9e33a19543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dd4a586d0dc64f0bb06fd81c9b8da781",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 443M/443M [00:29&lt;00:00, 15.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54e49747d10b4812b5aca7f8bc4c4b26"
          }
        },
        "72401569fa2846c8bb541c8cec5b3601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6494bf53b28b4fedb70e188ba8e8ffef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd4a586d0dc64f0bb06fd81c9b8da781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54e49747d10b4812b5aca7f8bc4c4b26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor-roris/ML-learning/blob/master/QuestionAnswering/TAPAS-Transformers_FinetuningTapasForQuestionAnsweringOnSQA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5Ds1ZM41KC9"
      },
      "source": [
        "# TAPAS - Transformers - Fine-tuning \n",
        "\n",
        "Notebook of an example of fine-tuning of TAPAS Transformers from the [Niels Rogge github](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/TAPAS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuaVfmt5gioc"
      },
      "source": [
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "* Original TAPAS paper (ACL 2020): https://www.aclweb.org/anthology/2020.acl-main.398/\n",
        "* Follow-up paper on intermediate pre-training (EMMNLP Findings 2020): https://www.aclweb.org/anthology/2020.findings-emnlp.27/\n",
        "* Original Github repository: https://github.com/google-research/tapas\n",
        "* Blog post: https://ai.googleblog.com/2020/04/using-neural-networks-to-find-answers.html\n",
        "\n",
        "TAPAS is an algorithm that (among other tasks) can answer questions about tabular data. It is essentially a BERT model with relative position embeddings and additional token type ids that encode tabular structure, and 2 classification heads on top: one for **cell selection** and one for (optionally) performing an **aggregation** among selected cells (such as summing or counting).\n",
        "\n",
        "Similar to BERT, the base `TapasModel` is pre-trained using the masked language modeling (MLM) objective on a large collection of tables from Wikipedia and associated texts. In addition, the authors further pre-trained the model on an second task (table entailment) to increase the numerical reasoning capabilities of TAPAS (as explained in the follow-up paper), which further improves performance on downstream tasks. \n",
        "\n",
        "In this notebook, we are going to fine-tune `TapasForQuestionAnswering` on [Sequential Question Answering (SQA)](https://www.microsoft.com/en-us/research/publication/search-based-neural-structured-learning-sequential-question-answering/), a dataset built by Microsoft Research which deals with asking questions related to a table in a **conversational set-up**. We are going to do so as in the original paper, by adding a randomly initialized cell selection head on top of the pre-trained base model (note that SQA does not have questions that involve aggregation and hence no aggregation head), and then fine-tuning them altogether.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6wFDNdOgp8f"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWonUVA3gtV_"
      },
      "source": [
        "First, we install both the Transformers library as well as the dependency on [`torch-scatter`](https://github.com/rusty1s/pytorch_scatter), which the model requires."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUMrt5Ow_PEA",
        "outputId": "36bfadd6-a4f7-4536-ae5f-17cbb75e3621"
      },
      "source": [
        "! rm -r transformers\n",
        "! git clone https://github.com/huggingface/transformers.git\n",
        "! cd transformers\n",
        "! pip install ./transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'transformers': No such file or directory\n",
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 70787, done.\u001b[K\n",
            "remote: Counting objects: 100% (876/876), done.\u001b[K\n",
            "remote: Compressing objects: 100% (442/442), done.\u001b[K\n",
            "remote: Total 70787 (delta 454), reused 684 (delta 364), pack-reused 69911\u001b[K\n",
            "Receiving objects: 100% (70787/70787), 53.96 MiB | 23.96 MiB/s, done.\n",
            "Resolving deltas: 100% (50026/50026), done.\n",
            "Processing ./transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (4.41.1)\n",
            "Collecting huggingface-hub>=0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 30.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (3.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (20.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (2020.12.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.6.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.6.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.6.0.dev0) (2.4.7)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.6.0.dev0-cp37-none-any.whl size=2116979 sha256=4d46990ef0745d7d280aed89c82f538d7db7a558692a6b1242f0a7241ecb9f01\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d72rd8ve/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "Successfully built transformers\n",
            "Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0.dev0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx4u09iTyRjY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed84c1b6-0fdd-4145-dfbb-6b1606b50632"
      },
      "source": [
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▏                               | 10kB 19.0MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 25.7MB/s eta 0:00:01\r\u001b[K     |▍                               | 30kB 30.6MB/s eta 0:00:01\r\u001b[K     |▌                               | 40kB 9.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 51kB 11.1MB/s eta 0:00:01\r\u001b[K     |▊                               | 61kB 12.7MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 14.0MB/s eta 0:00:01\r\u001b[K     |█                               | 81kB 9.8MB/s eta 0:00:01\r\u001b[K     |█▏                              | 92kB 10.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 102kB 11.6MB/s eta 0:00:01\r\u001b[K     |█▍                              | 112kB 11.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 122kB 11.6MB/s eta 0:00:01\r\u001b[K     |█▊                              | 133kB 11.6MB/s eta 0:00:01\r\u001b[K     |█▉                              | 143kB 11.6MB/s eta 0:00:01\r\u001b[K     |██                              | 153kB 11.6MB/s eta 0:00:01\r\u001b[K     |██                              | 163kB 11.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 174kB 11.6MB/s eta 0:00:01\r\u001b[K     |██▎                             | 184kB 11.6MB/s eta 0:00:01\r\u001b[K     |██▍                             | 194kB 11.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 204kB 11.6MB/s eta 0:00:01\r\u001b[K     |██▊                             | 215kB 11.6MB/s eta 0:00:01\r\u001b[K     |██▉                             | 225kB 11.6MB/s eta 0:00:01\r\u001b[K     |███                             | 235kB 11.6MB/s eta 0:00:01\r\u001b[K     |███                             | 245kB 11.6MB/s eta 0:00:01\r\u001b[K     |███▏                            | 256kB 11.6MB/s eta 0:00:01\r\u001b[K     |███▍                            | 266kB 11.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 276kB 11.6MB/s eta 0:00:01\r\u001b[K     |███▋                            | 286kB 11.6MB/s eta 0:00:01\r\u001b[K     |███▊                            | 296kB 11.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 307kB 11.6MB/s eta 0:00:01\r\u001b[K     |████                            | 317kB 11.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 327kB 11.6MB/s eta 0:00:01\r\u001b[K     |████▎                           | 337kB 11.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 348kB 11.6MB/s eta 0:00:01\r\u001b[K     |████▌                           | 358kB 11.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 368kB 11.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 378kB 11.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 389kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 399kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 409kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 419kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 430kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 440kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 450kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 460kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 471kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 481kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 491kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 501kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 512kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 522kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 532kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 542kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 552kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 563kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 573kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 583kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 593kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 604kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 614kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 624kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 634kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 645kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 655kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 665kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 675kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 686kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 696kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 706kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 716kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 727kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 737kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 747kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 757kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 768kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 778kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 788kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 798kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 808kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 819kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 829kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 839kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 849kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 860kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 870kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 880kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 890kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 901kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 911kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 921kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 931kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 942kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 952kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 962kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 972kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 983kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 993kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 1.0MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 1.0MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 1.0MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.0MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.0MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 1.1MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 1.1MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 1.1MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 1.1MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 1.1MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 1.1MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.1MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.1MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.1MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.1MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.2MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.2MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.2MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.2MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.2MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.2MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.2MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.2MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 1.2MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.2MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.3MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.3MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.3MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.3MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.3MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.3MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.3MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.3MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.3MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.4MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.4MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.4MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.4MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.4MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.4MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.4MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.4MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.4MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.4MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.5MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.5MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.5MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.5MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.5MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.5MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.5MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.5MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.5MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.5MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.6MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.6MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.6MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.6MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.6MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.6MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.6MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.6MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.6MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.6MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.7MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.7MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.7MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.7MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.7MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.7MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.7MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.7MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.7MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.8MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.8MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.8MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.8MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.8MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.8MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.8MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.8MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.8MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.8MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.9MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.9MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.9MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.9MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.9MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.9MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.9MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.9MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.9MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.9MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 2.0MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 2.0MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 2.0MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.0MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.0MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 2.0MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 2.0MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 2.0MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 2.0MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 2.0MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 2.1MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.1MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.1MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 2.1MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 2.1MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 2.1MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 2.1MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 2.1MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 2.1MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.2MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 2.2MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 2.2MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 2.2MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 2.2MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 2.2MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 2.2MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.2MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.2MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.2MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 2.3MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.3MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.3MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.3MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 2.3MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.3MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.3MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 2.3MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.3MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.3MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.4MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 2.4MB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 2.4MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.4MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.4MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 2.4MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.4MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 2.4MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 2.4MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.4MB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.5MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.5MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.5MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.5MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 2.5MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.5MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.5MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.5MB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 2.5MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.5MB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.6MB 11.6MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSZfmBt0meYm"
      },
      "source": [
        "We also install a small portion from the SQA training dataset, for demonstration purposes. This is a TSV file containing table-question pairs. Besides this, we also download the `table_csv` directory, which contains the actual tabular data.\n",
        "\n",
        "Note that you can download the entire SQA dataset on the [official website](https://www.microsoft.com/en-us/download/details.aspx?id=54253)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsuwgDEU4J_f"
      },
      "source": [
        "import requests, zipfile, io\n",
        "import os\n",
        "\n",
        "def download_files(dir_name):\n",
        "  if not os.path.exists(dir_name): \n",
        "    # 28 training examples from the SQA training set + table csv data\n",
        "    urls = [\"https://www.dropbox.com/s/2p6ez9xro357i63/sqa_train_set_28_examples.zip?dl=1\",\n",
        "            \"https://www.dropbox.com/s/abhum8ssuow87h6/table_csv.zip?dl=1\"\n",
        "    ]\n",
        "    for url in urls:\n",
        "      r = requests.get(url)\n",
        "      z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "      z.extractall()\n",
        "\n",
        "dir_name = \"sqa_data\"\n",
        "download_files(dir_name)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18LJJ8BtMg_u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e80ab1ca-babb-49f9-ba31-c6018d9c3acf"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  sqa_train_set_28_examples.xlsx  table_csv\ttransformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTszl31oMvz6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb79f4b0-dd72-40e5-d9d4-eb43dfd6ebb0"
      },
      "source": [
        "!ls table_csv | head -10\n",
        "\n",
        "print(\"...\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200_12.csv\n",
            "200_14.csv\n",
            "200_18.csv\n",
            "200_22.csv\n",
            "200_25.csv\n",
            "200_28.csv\n",
            "200_30.csv\n",
            "200_33.csv\n",
            "200_35.csv\n",
            "200_3.csv\n",
            "...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oliDlejoNMK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "836605b8-1837-4c22-92a4-2ff8f5285e05"
      },
      "source": [
        "!cat table_csv/200_12.csv"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Year,Award,Category,Nominated work,Result\n",
            "1979,Olivier Award,Best Actress in a Revival,Once in a Lifetime,Won\n",
            "1981,Tony Award,Best Featured in a Play,Piaf!,Nominated\n",
            "1981,Drama Desk Award,Outstanding Featured Actress in a Play,Piaf!,Nominated\n",
            "1984,Olivier Award,Best Actress in a Revival,Twelfth Night,Nominated\n",
            "1984,Olivier Award,Best Actress in a Supporting Role,The Time of Your Life,Nominated\n",
            "1985,Olivier Award,Best Performance in a Supporting Role,Mother Courage,Nominated\n",
            "1986,Tony Award,Best Featured Actress in a Play,Loot,Nominated\n",
            "1986,Drama Desk Award,Outstanding Featured Actress in a Play,Loot,Nominated\n",
            "1989/90,Olivier Award,Best Performance in a Supporting Role,Othello,Nominated\n",
            "1991,Olivier Award,Best Actress in a Supporting Role,The Crucible,Nominated\n",
            "1992,BAFTA TV Award,Best Actress,Prime Suspect,Nominated\n",
            "1993,BAFTA TV Award,Best Actress,Love Hurts,Nominated\n",
            "1996,Olivier Award,Best Actress,The Glass Menagerie,Nominated\n",
            "1998,BAFTA Film Award,Best Supporting Actress,Wilde,Nominated\n",
            "1998,Olivier Award,Best Actress,Electra,Won\n",
            "1999,Tony Award,Best Actress in a Play,Electra,Nominated\n",
            "1999,Drama Desk Award,Outstanding Actress in a Play,Electra,Nominated\n",
            "2002,Olivier Award,Best Actress,Boston Marriage,Nominated\n",
            "2006,Tony Award,Best Featured Actress in a Play,Awake and Sing!,Nominated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPrYJOn81f0D"
      },
      "source": [
        "## Prepare the data \n",
        "\n",
        "Let's look at the first few rows of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "2X27wyd805D8",
        "outputId": "64079864-abde-49f4-f647-d2720a714b0a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_excel(\"sqa_train_set_28_examples.xlsx\")\n",
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>annotator</th>\n",
              "      <th>position</th>\n",
              "      <th>question</th>\n",
              "      <th>table_file</th>\n",
              "      <th>answer_coordinates</th>\n",
              "      <th>answer_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nt-639</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>where are the players from?</td>\n",
              "      <td>table_csv/203_149.csv</td>\n",
              "      <td>['(0, 4)', '(1, 4)', '(2, 4)', '(3, 4)', '(4, ...</td>\n",
              "      <td>['Louisiana State University', 'Valley HS (Las...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nt-639</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>which player went to louisiana state university?</td>\n",
              "      <td>table_csv/203_149.csv</td>\n",
              "      <td>['(0, 1)']</td>\n",
              "      <td>['Ben McDonald']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nt-639</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>who are the players?</td>\n",
              "      <td>table_csv/203_149.csv</td>\n",
              "      <td>['(0, 1)', '(1, 1)', '(2, 1)', '(3, 1)', '(4, ...</td>\n",
              "      <td>['Ben McDonald', 'Tyler Houston', 'Roger Salke...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nt-639</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>which ones are in the top 26 picks?</td>\n",
              "      <td>table_csv/203_149.csv</td>\n",
              "      <td>['(0, 1)', '(1, 1)', '(2, 1)', '(3, 1)', '(4, ...</td>\n",
              "      <td>['Ben McDonald', 'Tyler Houston', 'Roger Salke...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nt-639</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>and of those, who is from louisiana state univ...</td>\n",
              "      <td>table_csv/203_149.csv</td>\n",
              "      <td>['(0, 1)']</td>\n",
              "      <td>['Ben McDonald']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  ...                                        answer_text\n",
              "0  nt-639  ...  ['Louisiana State University', 'Valley HS (Las...\n",
              "1  nt-639  ...                                   ['Ben McDonald']\n",
              "2  nt-639  ...  ['Ben McDonald', 'Tyler Houston', 'Roger Salke...\n",
              "3  nt-639  ...  ['Ben McDonald', 'Tyler Houston', 'Roger Salke...\n",
              "4  nt-639  ...                                   ['Ben McDonald']\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMJ4dNBV1oj6"
      },
      "source": [
        "As you can see, each row corresponds to a question related to a table. \n",
        "* The `position` column identifies whether the question is the first, second, ... in a sequence of questions related to a table. \n",
        "* The `table_file` column identifies the name of the table file, which refers to a CSV file in the `table_csv` directory.\n",
        "* The `answer_coordinates` and `answer_text` columns indicate the answer to the question. The `answer_coordinates` is a list of tuples, each tuple being a (row_index, column_index) pair. The `answer_text` column is a list of strings, indicating the cell values.\n",
        "\n",
        "However, the `answer_coordinates` and `answer_text` columns are currently not recognized as real Python lists of Python tuples and strings respectively. Let's do that first using the `.literal_eval()`function of the `ast` module:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "BAovAs5s1k10",
        "outputId": "a42ce671-35de-4b16-ad5a-e6bd4414a23a"
      },
      "source": [
        "import ast\n",
        "\n",
        "def _parse_answer_coordinates(answer_coordinate_str):\n",
        "  \"\"\"Parses the answer_coordinates of a question.\n",
        "  Args:\n",
        "    answer_coordinate_str: A string representation of a Python list of tuple\n",
        "      strings.\n",
        "      For example: \"['(1, 4)','(1, 3)', ...]\"\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    answer_coordinates = []\n",
        "    # make a list of strings\n",
        "    coords = ast.literal_eval(answer_coordinate_str)\n",
        "    # parse each string as a tuple\n",
        "    for row_index, column_index in sorted(\n",
        "        ast.literal_eval(coord) for coord in coords):\n",
        "      answer_coordinates.append((row_index, column_index))\n",
        "  except SyntaxError:\n",
        "    raise ValueError('Unable to evaluate %s' % answer_coordinate_str)\n",
        "  \n",
        "  return answer_coordinates\n",
        "\n",
        "\n",
        "def _parse_answer_text(answer_text):\n",
        "  \"\"\"Populates the answer_texts field of `answer` by parsing `answer_text`.\n",
        "  Args:\n",
        "    answer_text: A string representation of a Python list of strings.\n",
        "      For example: \"[u'test', u'hello', ...]\"\n",
        "    answer: an Answer object.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    answer = []\n",
        "    for value in ast.literal_eval(answer_text):\n",
        "      answer.append(value)\n",
        "  except SyntaxError:\n",
        "    raise ValueError('Unable to evaluate %s' % answer_text)\n",
        "\n",
        "  return answer\n",
        "\n",
        "data['answer_coordinates'] = data['answer_coordinates'].apply(lambda coords_str: _parse_answer_coordinates(coords_str))\n",
        "data['answer_text'] = data['answer_text'].apply(lambda txt: _parse_answer_text(txt))\n",
        "\n",
        "data.head(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>annotator</th>\n",
              "      <th>position</th>\n",
              "      <th>question</th>\n",
              "      <th>table_file</th>\n",
              "      <th>answer_coordinates</th>\n",
              "      <th>answer_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nt-639</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>where are the players from?</td>\n",
              "      <td>table_csv/203_149.csv</td>\n",
              "      <td>[(0, 4), (1, 4), (2, 4), (3, 4), (4, 4), (5, 4...</td>\n",
              "      <td>[Louisiana State University, Valley HS (Las Ve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nt-639</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>which player went to louisiana state university?</td>\n",
              "      <td>table_csv/203_149.csv</td>\n",
              "      <td>[(0, 1)]</td>\n",
              "      <td>[Ben McDonald]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nt-639</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>who are the players?</td>\n",
              "      <td>table_csv/203_149.csv</td>\n",
              "      <td>[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1...</td>\n",
              "      <td>[Ben McDonald, Tyler Houston, Roger Salkeld, J...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nt-639</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>which ones are in the top 26 picks?</td>\n",
              "      <td>table_csv/203_149.csv</td>\n",
              "      <td>[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1...</td>\n",
              "      <td>[Ben McDonald, Tyler Houston, Roger Salkeld, J...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nt-639</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>and of those, who is from louisiana state univ...</td>\n",
              "      <td>table_csv/203_149.csv</td>\n",
              "      <td>[(0, 1)]</td>\n",
              "      <td>[Ben McDonald]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>nt-639</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>who are the players in the top 26?</td>\n",
              "      <td>table_csv/203_149.csv</td>\n",
              "      <td>[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1...</td>\n",
              "      <td>[Ben McDonald, Tyler Houston, Roger Salkeld, J...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>nt-639</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>of those, which one was from louisiana state u...</td>\n",
              "      <td>table_csv/203_149.csv</td>\n",
              "      <td>[(0, 1)]</td>\n",
              "      <td>[Ben McDonald]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>nt-11649</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>what are all the names of the teams?</td>\n",
              "      <td>table_csv/204_135.csv</td>\n",
              "      <td>[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1...</td>\n",
              "      <td>[Cordoba CF, CD Malaga, Granada CF, UD Las Pal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>nt-11649</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>of these, which teams had any losses?</td>\n",
              "      <td>table_csv/204_135.csv</td>\n",
              "      <td>[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1...</td>\n",
              "      <td>[Cordoba CF, CD Malaga, Granada CF, UD Las Pal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>nt-11649</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>of these teams, which had more than 21 losses?</td>\n",
              "      <td>table_csv/204_135.csv</td>\n",
              "      <td>[(15, 1)]</td>\n",
              "      <td>[CD Villarrobledo]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ...                                        answer_text\n",
              "0    nt-639  ...  [Louisiana State University, Valley HS (Las Ve...\n",
              "1    nt-639  ...                                     [Ben McDonald]\n",
              "2    nt-639  ...  [Ben McDonald, Tyler Houston, Roger Salkeld, J...\n",
              "3    nt-639  ...  [Ben McDonald, Tyler Houston, Roger Salkeld, J...\n",
              "4    nt-639  ...                                     [Ben McDonald]\n",
              "5    nt-639  ...  [Ben McDonald, Tyler Houston, Roger Salkeld, J...\n",
              "6    nt-639  ...                                     [Ben McDonald]\n",
              "7  nt-11649  ...  [Cordoba CF, CD Malaga, Granada CF, UD Las Pal...\n",
              "8  nt-11649  ...  [Cordoba CF, CD Malaga, Granada CF, UD Las Pal...\n",
              "9  nt-11649  ...                                 [CD Villarrobledo]\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7FYPpdW5dY4"
      },
      "source": [
        "Let's create a new dataframe that groups questions which are asked in a sequence related to the table. We can do this by adding a `sequence_id` column, which is a combination of the `id` and `annotator` columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "O1Quo0FL7h9-",
        "outputId": "8acf152f-fd2b-4f12-98cf-626595dd8929"
      },
      "source": [
        "def get_sequence_id(example_id, annotator):\n",
        "  if \"-\" in str(annotator):\n",
        "    raise ValueError('\"-\" not allowed in annotator.')\n",
        "  return f\"{example_id}-{annotator}\"\n",
        "\n",
        "data['sequence_id'] = data.apply(lambda x: get_sequence_id(x.id, x.annotator), axis=1)\n",
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>annotator</th>\n",
              "      <th>position</th>\n",
              "      <th>question</th>\n",
              "      <th>table_file</th>\n",
              "      <th>answer_coordinates</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>sequence_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nt-639</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>where are the players from?</td>\n",
              "      <td>table_csv/203_149.csv</td>\n",
              "      <td>[(0, 4), (1, 4), (2, 4), (3, 4), (4, 4), (5, 4...</td>\n",
              "      <td>[Louisiana State University, Valley HS (Las Ve...</td>\n",
              "      <td>nt-639-0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nt-639</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>which player went to louisiana state university?</td>\n",
              "      <td>table_csv/203_149.csv</td>\n",
              "      <td>[(0, 1)]</td>\n",
              "      <td>[Ben McDonald]</td>\n",
              "      <td>nt-639-0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nt-639</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>who are the players?</td>\n",
              "      <td>table_csv/203_149.csv</td>\n",
              "      <td>[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1...</td>\n",
              "      <td>[Ben McDonald, Tyler Houston, Roger Salkeld, J...</td>\n",
              "      <td>nt-639-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nt-639</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>which ones are in the top 26 picks?</td>\n",
              "      <td>table_csv/203_149.csv</td>\n",
              "      <td>[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1...</td>\n",
              "      <td>[Ben McDonald, Tyler Houston, Roger Salkeld, J...</td>\n",
              "      <td>nt-639-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nt-639</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>and of those, who is from louisiana state univ...</td>\n",
              "      <td>table_csv/203_149.csv</td>\n",
              "      <td>[(0, 1)]</td>\n",
              "      <td>[Ben McDonald]</td>\n",
              "      <td>nt-639-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  ...  sequence_id\n",
              "0  nt-639  ...     nt-639-0\n",
              "1  nt-639  ...     nt-639-0\n",
              "2  nt-639  ...     nt-639-1\n",
              "3  nt-639  ...     nt-639-1\n",
              "4  nt-639  ...     nt-639-1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "-uPpds5D762B",
        "outputId": "8f9b840e-deee-4c9a-ca93-938ac25a6704"
      },
      "source": [
        "# let's group table-question pairs by sequence id, and remove some columns we don't need \n",
        "grouped = data.groupby(by='sequence_id').agg(lambda x: x.tolist())\n",
        "grouped = grouped.drop(columns=['id', 'annotator', 'position'])\n",
        "grouped['table_file'] = grouped['table_file'].apply(lambda x: x[0])\n",
        "grouped.head(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>table_file</th>\n",
              "      <th>answer_coordinates</th>\n",
              "      <th>answer_text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sequence_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ns-1292-0</th>\n",
              "      <td>[who are all the athletes?, where are they fro...</td>\n",
              "      <td>table_csv/204_521.csv</td>\n",
              "      <td>[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, ...</td>\n",
              "      <td>[[Tommy Green, Janis Dalins, Ugo Frigerio, Kar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nt-10730-0</th>\n",
              "      <td>[what was the production numbers of each revol...</td>\n",
              "      <td>table_csv/203_253.csv</td>\n",
              "      <td>[[(0, 4), (1, 4), (2, 4), (3, 4), (4, 4), (5, ...</td>\n",
              "      <td>[[1,900 (estimated), 14,500 (estimated), 6,000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nt-10730-1</th>\n",
              "      <td>[what three revolver models had the least amou...</td>\n",
              "      <td>table_csv/203_253.csv</td>\n",
              "      <td>[[(0, 0), (6, 0), (7, 0)], [(0, 0)]]</td>\n",
              "      <td>[[Remington-Beals Army Model Revolver, New Mod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nt-10730-2</th>\n",
              "      <td>[what are all of the remington models?, how ma...</td>\n",
              "      <td>table_csv/203_253.csv</td>\n",
              "      <td>[[(0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (5, ...</td>\n",
              "      <td>[[Remington-Beals Army Model Revolver, Remingt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nt-11649-0</th>\n",
              "      <td>[what are all the names of the teams?, of thes...</td>\n",
              "      <td>table_csv/204_135.csv</td>\n",
              "      <td>[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, ...</td>\n",
              "      <td>[[Cordoba CF, CD Malaga, Granada CF, UD Las Pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nt-11649-1</th>\n",
              "      <td>[what are the losses?, what team had more than...</td>\n",
              "      <td>table_csv/204_135.csv</td>\n",
              "      <td>[[(0, 6), (1, 6), (2, 6), (3, 6), (4, 6), (5, ...</td>\n",
              "      <td>[[6, 6, 9, 10, 10, 12, 12, 11, 13, 14, 15, 14,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nt-11649-2</th>\n",
              "      <td>[what were all the teams?, what were the loss ...</td>\n",
              "      <td>table_csv/204_135.csv</td>\n",
              "      <td>[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, ...</td>\n",
              "      <td>[[Cordoba CF, CD Malaga, Granada CF, UD Las Pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nt-639-0</th>\n",
              "      <td>[where are the players from?, which player wen...</td>\n",
              "      <td>table_csv/203_149.csv</td>\n",
              "      <td>[[(0, 4), (1, 4), (2, 4), (3, 4), (4, 4), (5, ...</td>\n",
              "      <td>[[Louisiana State University, Valley HS (Las V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nt-639-1</th>\n",
              "      <td>[who are the players?, which ones are in the t...</td>\n",
              "      <td>table_csv/203_149.csv</td>\n",
              "      <td>[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, ...</td>\n",
              "      <td>[[Ben McDonald, Tyler Houston, Roger Salkeld, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nt-639-2</th>\n",
              "      <td>[who are the players in the top 26?, of those,...</td>\n",
              "      <td>table_csv/203_149.csv</td>\n",
              "      <td>[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, ...</td>\n",
              "      <td>[[Ben McDonald, Tyler Houston, Roger Salkeld, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      question  ...                                        answer_text\n",
              "sequence_id                                                     ...                                                   \n",
              "ns-1292-0    [who are all the athletes?, where are they fro...  ...  [[Tommy Green, Janis Dalins, Ugo Frigerio, Kar...\n",
              "nt-10730-0   [what was the production numbers of each revol...  ...  [[1,900 (estimated), 14,500 (estimated), 6,000...\n",
              "nt-10730-1   [what three revolver models had the least amou...  ...  [[Remington-Beals Army Model Revolver, New Mod...\n",
              "nt-10730-2   [what are all of the remington models?, how ma...  ...  [[Remington-Beals Army Model Revolver, Remingt...\n",
              "nt-11649-0   [what are all the names of the teams?, of thes...  ...  [[Cordoba CF, CD Malaga, Granada CF, UD Las Pa...\n",
              "nt-11649-1   [what are the losses?, what team had more than...  ...  [[6, 6, 9, 10, 10, 12, 12, 11, 13, 14, 15, 14,...\n",
              "nt-11649-2   [what were all the teams?, what were the loss ...  ...  [[Cordoba CF, CD Malaga, Granada CF, UD Las Pa...\n",
              "nt-639-0     [where are the players from?, which player wen...  ...  [[Louisiana State University, Valley HS (Las V...\n",
              "nt-639-1     [who are the players?, which ones are in the t...  ...  [[Ben McDonald, Tyler Houston, Roger Salkeld, ...\n",
              "nt-639-2     [who are the players in the top 26?, of those,...  ...  [[Ben McDonald, Tyler Houston, Roger Salkeld, ...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6RKTkSeLLyJ"
      },
      "source": [
        "Each row in the dataframe above now consists of a **table and one or more questions** which are asked in a **sequence**. Let's visualize the first row, i.e. a table, together with its queries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "J-dTi5omLdN_",
        "outputId": "a9bb79a2-5897-45c3-cc0a-5fd96475dc57"
      },
      "source": [
        "# path to the directory containing all csv files\n",
        "table_csv_path = \"table_csv\"\n",
        "\n",
        "item = grouped.iloc[0]\n",
        "table = pd.read_csv(table_csv_path + item.table_file[9:]).astype(str) \n",
        "\n",
        "display(table)\n",
        "print(\"\")\n",
        "print(item.question)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rank</th>\n",
              "      <th>Name</th>\n",
              "      <th>Nationality</th>\n",
              "      <th>Time (hand)</th>\n",
              "      <th>Notes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nan</td>\n",
              "      <td>Tommy Green</td>\n",
              "      <td>Great Britain</td>\n",
              "      <td>4:50:10</td>\n",
              "      <td>OR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nan</td>\n",
              "      <td>Janis Dalins</td>\n",
              "      <td>Latvia</td>\n",
              "      <td>4:57:20</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nan</td>\n",
              "      <td>Ugo Frigerio</td>\n",
              "      <td>Italy</td>\n",
              "      <td>4:59:06</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Karl Hahnel</td>\n",
              "      <td>Germany</td>\n",
              "      <td>5:06:06</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Ettore Rivolta</td>\n",
              "      <td>Italy</td>\n",
              "      <td>5:07:39</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.0</td>\n",
              "      <td>Paul Sievert</td>\n",
              "      <td>Germany</td>\n",
              "      <td>5:16:41</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7.0</td>\n",
              "      <td>Henri Quintric</td>\n",
              "      <td>France</td>\n",
              "      <td>5:27:25</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8.0</td>\n",
              "      <td>Ernie Crosbie</td>\n",
              "      <td>United States</td>\n",
              "      <td>5:28:02</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9.0</td>\n",
              "      <td>Bill Chisholm</td>\n",
              "      <td>United States</td>\n",
              "      <td>5:51:00</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10.0</td>\n",
              "      <td>Alfred Maasik</td>\n",
              "      <td>Estonia</td>\n",
              "      <td>6:19:00</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>nan</td>\n",
              "      <td>Henry Cieman</td>\n",
              "      <td>Canada</td>\n",
              "      <td>nan</td>\n",
              "      <td>DNF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>nan</td>\n",
              "      <td>John Moralis</td>\n",
              "      <td>Greece</td>\n",
              "      <td>nan</td>\n",
              "      <td>DNF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>nan</td>\n",
              "      <td>Francesco Pretti</td>\n",
              "      <td>Italy</td>\n",
              "      <td>nan</td>\n",
              "      <td>DNF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>nan</td>\n",
              "      <td>Arthur Tell Schwab</td>\n",
              "      <td>Switzerland</td>\n",
              "      <td>nan</td>\n",
              "      <td>DNF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>nan</td>\n",
              "      <td>Harry Hinkel</td>\n",
              "      <td>United States</td>\n",
              "      <td>nan</td>\n",
              "      <td>DNF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Rank                Name    Nationality Time (hand) Notes\n",
              "0    nan         Tommy Green  Great Britain     4:50:10    OR\n",
              "1    nan        Janis Dalins         Latvia     4:57:20   nan\n",
              "2    nan        Ugo Frigerio          Italy     4:59:06   nan\n",
              "3    4.0         Karl Hahnel        Germany     5:06:06   nan\n",
              "4    5.0      Ettore Rivolta          Italy     5:07:39   nan\n",
              "5    6.0        Paul Sievert        Germany     5:16:41   nan\n",
              "6    7.0      Henri Quintric         France     5:27:25   nan\n",
              "7    8.0       Ernie Crosbie  United States     5:28:02   nan\n",
              "8    9.0       Bill Chisholm  United States     5:51:00   nan\n",
              "9   10.0       Alfred Maasik        Estonia     6:19:00   nan\n",
              "10   nan        Henry Cieman         Canada         nan   DNF\n",
              "11   nan        John Moralis         Greece         nan   DNF\n",
              "12   nan    Francesco Pretti          Italy         nan   DNF\n",
              "13   nan  Arthur Tell Schwab    Switzerland         nan   DNF\n",
              "14   nan        Harry Hinkel  United States         nan   DNF"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "['who are all the athletes?', 'where are they from?', 'along with paul sievert, which athlete is from germany?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw8MqIExLnnq"
      },
      "source": [
        "We can see that there are 3 sequential questions asked related to the contents of the table. \n",
        "\n",
        "We can now use `TapasTokenizer` to batch encode this, as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5iU5byAICWb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "0d1c74530dc6430189b8e57591d98e29",
            "d18f63c05579474b9ccbdbb83d18d3e7",
            "00060e719684477d831f33d1985839e5",
            "7cb58557540d4246a2aef673bc6a22c7",
            "c266b536b0c14e6e863dd2e829166b01",
            "7c6c727318fe43109e91d74d3ab64a65",
            "3d66c996c582463e87dbdbdabb4f5bb8",
            "0a15d57b702742a5a3331b5d42466404",
            "a5152a8b555045e3812c7b773c9efaec",
            "c426ac608dda407d836f1add28538aa5",
            "816d4f80aaa74d4d8bb21252ea01703b",
            "3ef7007065684238982ed1d77b76febf",
            "83b191ff25b243f9be12bd64c25292b1",
            "1ae39050afce404392b9be61c0c2a801",
            "29115da651044e068722783bcc8ebc87",
            "43b3d1819c4446a3923043ae66f9cd7e",
            "9e9b93a0035d4157a4b327c6571597ed",
            "38db1eafdd724b3f8f5bcde8841e67d8",
            "82f2196a08aa421fb30643504dbec5e5",
            "fa4df53ff99442639c1bef27cba544e3",
            "4863cb7777e84b4fb96fec70f09f0f02",
            "dd644514150447a5a51b699c143599f5",
            "e4bd0a48e7ca4596bf2ecf53f7e177c0",
            "46ec528ecb2b4d87afd207b9f9adaf2d"
          ]
        },
        "outputId": "a356b4cc-1fc3-4816-c52b-ff63bcbcd914"
      },
      "source": [
        "import torch\n",
        "from transformers import TapasTokenizer\n",
        "\n",
        "# initialize the tokenizer\n",
        "tokenizer = TapasTokenizer.from_pretrained(\"google/tapas-base\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d1c74530dc6430189b8e57591d98e29",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=262028.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5152a8b555045e3812c7b773c9efaec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=154.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e9b93a0035d4157a4b327c6571597ed",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=490.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qOBiUPEGgK8",
        "outputId": "29a0f998-ea34-491f-f4d5-988f17514829"
      },
      "source": [
        "encoding = tokenizer(table=table, queries=item.question, answer_coordinates=item.answer_coordinates, answer_text=item.answer_text,\n",
        "                     truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "encoding.keys()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'labels', 'numeric_values', 'numeric_values_scale', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2JRiKjPRHAF"
      },
      "source": [
        "TAPAS basically flattens every table-question pair before feeding it into a BERT like model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "id": "lhipz2_GRNKQ",
        "outputId": "ed6808b0-a4fb-421b-f380-88e29261302d"
      },
      "source": [
        "tokenizer.decode(encoding[\"input_ids\"][0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] who are all the athletes? [SEP] rank name nationality time ( hand ) notes [EMPTY] tommy green great britain 4 : 50 : 10 or [EMPTY] janis dalins latvia 4 : 57 : 20 [EMPTY] [EMPTY] ugo frigerio italy 4 : 59 : 06 [EMPTY] 4. 0 karl hahnel germany 5 : 06 : 06 [EMPTY] 5. 0 ettore rivolta italy 5 : 07 : 39 [EMPTY] 6. 0 paul sievert germany 5 : 16 : 41 [EMPTY] 7. 0 henri quintric france 5 : 27 : 25 [EMPTY] 8. 0 ernie crosbie united states 5 : 28 : 02 [EMPTY] 9. 0 bill chisholm united states 5 : 51 : 00 [EMPTY] 10. 0 alfred maasik estonia 6 : 19 : 00 [EMPTY] [EMPTY] henry cieman canada [EMPTY] dnf [EMPTY] john moralis greece [EMPTY] dnf [EMPTY] francesco pretti italy [EMPTY] dnf [EMPTY] arthur tell schwab switzerland [EMPTY] dnf [EMPTY] harry hinkel united states [EMPTY] dnf [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVeB5IPaN5oN"
      },
      "source": [
        "The `token_type_ids` ([here](https://huggingface.co/transformers/glossary.html#token-type-ids) more info about it) created here will be of shape (batch_size, sequence_length, 7), as TAPAS uses 7 different token types to encode tabular structure. Let's verify this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM0v-pwbN6gR"
      },
      "source": [
        "assert encoding[\"token_type_ids\"].shape == (3, 512, 7)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMt7cWJMLvue"
      },
      "source": [
        "\n",
        "\n",
        "One thing we can verify is whether the `prev_label` token type ids are created correctly. These indicate which tokens were (part of) an answer to the previous table-question pair. \n",
        "\n",
        "The prev_label token type ids of the first example in a batch must always be zero (since there's no previous table-question pair). Let's verify this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytUk-H1yL9cc"
      },
      "source": [
        "assert encoding[\"token_type_ids\"][0][:,3].sum() == 0"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ_o-82nMfK5"
      },
      "source": [
        "However, the `prev_label` token type ids of the second table-question pair in the batch must be set to 1 for the tokens which were an answer to the previous (i.e. the first) table question pair in the batch. The answers to the first table-question pair are the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxT9h2LIMNt3",
        "outputId": "fd924da6-a08e-43d8-9927-8198315c66fa"
      },
      "source": [
        "print(item.answer_text[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Tommy Green', 'Janis Dalins', 'Ugo Frigerio', 'Karl Hahnel', 'Ettore Rivolta', 'Paul Sievert', 'Henri Quintric', 'Ernie Crosbie', 'Bill Chisholm', 'Alfred Maasik', 'Henry Cieman', 'John Moralis', 'Francesco Pretti', 'Arthur Tell Schwab', 'Harry Hinkel']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSUkMGAcMpfE"
      },
      "source": [
        "So let's now verify whether the `prev_label` ids of the second table-question pair are set correctly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv6P7OpJGxuu",
        "outputId": "95591f2f-7732-47fb-c3ba-04a53516d141"
      },
      "source": [
        "for id, prev_label in zip (encoding[\"input_ids\"][1], encoding[\"token_type_ids\"][1][:,3]):\n",
        "  if id != 0: # we skip padding tokens\n",
        "    print(tokenizer.decode([id]), prev_label.item())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] 0\n",
            "where 0\n",
            "are 0\n",
            "they 0\n",
            "from 0\n",
            "? 0\n",
            "[SEP] 0\n",
            "rank 0\n",
            "name 0\n",
            "nationality 0\n",
            "time 0\n",
            "( 0\n",
            "hand 0\n",
            ") 0\n",
            "notes 0\n",
            "[EMPTY] 0\n",
            "tommy 1\n",
            "green 1\n",
            "great 0\n",
            "britain 0\n",
            "4 0\n",
            ": 0\n",
            "50 0\n",
            ": 0\n",
            "10 0\n",
            "or 0\n",
            "[EMPTY] 0\n",
            "jan 1\n",
            "##is 1\n",
            "dali 1\n",
            "##ns 1\n",
            "latvia 0\n",
            "4 0\n",
            ": 0\n",
            "57 0\n",
            ": 0\n",
            "20 0\n",
            "[EMPTY] 0\n",
            "[EMPTY] 0\n",
            "u 1\n",
            "##go 1\n",
            "fr 1\n",
            "##iger 1\n",
            "##io 1\n",
            "italy 0\n",
            "4 0\n",
            ": 0\n",
            "59 0\n",
            ": 0\n",
            "06 0\n",
            "[EMPTY] 0\n",
            "4 0\n",
            ". 0\n",
            "0 0\n",
            "karl 1\n",
            "hahn 1\n",
            "##el 1\n",
            "germany 0\n",
            "5 0\n",
            ": 0\n",
            "06 0\n",
            ": 0\n",
            "06 0\n",
            "[EMPTY] 0\n",
            "5 0\n",
            ". 0\n",
            "0 0\n",
            "et 1\n",
            "##tore 1\n",
            "ri 1\n",
            "##vo 1\n",
            "##lta 1\n",
            "italy 0\n",
            "5 0\n",
            ": 0\n",
            "07 0\n",
            ": 0\n",
            "39 0\n",
            "[EMPTY] 0\n",
            "6 0\n",
            ". 0\n",
            "0 0\n",
            "paul 1\n",
            "si 1\n",
            "##ever 1\n",
            "##t 1\n",
            "germany 0\n",
            "5 0\n",
            ": 0\n",
            "16 0\n",
            ": 0\n",
            "41 0\n",
            "[EMPTY] 0\n",
            "7 0\n",
            ". 0\n",
            "0 0\n",
            "henri 1\n",
            "qui 1\n",
            "##nt 1\n",
            "##ric 1\n",
            "france 0\n",
            "5 0\n",
            ": 0\n",
            "27 0\n",
            ": 0\n",
            "25 0\n",
            "[EMPTY] 0\n",
            "8 0\n",
            ". 0\n",
            "0 0\n",
            "ernie 1\n",
            "cr 1\n",
            "##os 1\n",
            "##bie 1\n",
            "united 0\n",
            "states 0\n",
            "5 0\n",
            ": 0\n",
            "28 0\n",
            ": 0\n",
            "02 0\n",
            "[EMPTY] 0\n",
            "9 0\n",
            ". 0\n",
            "0 0\n",
            "bill 1\n",
            "chi 1\n",
            "##sho 1\n",
            "##lm 1\n",
            "united 0\n",
            "states 0\n",
            "5 0\n",
            ": 0\n",
            "51 0\n",
            ": 0\n",
            "00 0\n",
            "[EMPTY] 0\n",
            "10 0\n",
            ". 0\n",
            "0 0\n",
            "alfred 1\n",
            "ma 1\n",
            "##asi 1\n",
            "##k 1\n",
            "estonia 0\n",
            "6 0\n",
            ": 0\n",
            "19 0\n",
            ": 0\n",
            "00 0\n",
            "[EMPTY] 0\n",
            "[EMPTY] 0\n",
            "henry 1\n",
            "ci 1\n",
            "##eman 1\n",
            "canada 0\n",
            "[EMPTY] 0\n",
            "d 0\n",
            "##n 0\n",
            "##f 0\n",
            "[EMPTY] 0\n",
            "john 1\n",
            "moral 1\n",
            "##is 1\n",
            "greece 0\n",
            "[EMPTY] 0\n",
            "d 0\n",
            "##n 0\n",
            "##f 0\n",
            "[EMPTY] 0\n",
            "francesco 1\n",
            "pre 1\n",
            "##tti 1\n",
            "italy 0\n",
            "[EMPTY] 0\n",
            "d 0\n",
            "##n 0\n",
            "##f 0\n",
            "[EMPTY] 0\n",
            "arthur 1\n",
            "tell 1\n",
            "sc 1\n",
            "##hwa 1\n",
            "##b 1\n",
            "switzerland 0\n",
            "[EMPTY] 0\n",
            "d 0\n",
            "##n 0\n",
            "##f 0\n",
            "[EMPTY] 0\n",
            "harry 1\n",
            "hi 1\n",
            "##nk 1\n",
            "##el 1\n",
            "united 0\n",
            "states 0\n",
            "[EMPTY] 0\n",
            "d 0\n",
            "##n 0\n",
            "##f 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjVk49fO6u8H"
      },
      "source": [
        "This looks OK! Be sure to check this, because the token type ids are critical for the performance of TAPAS.\n",
        "\n",
        "Let's create a PyTorch dataset and corresponding dataloader. Note the __getitem__ method here: in order to properly set the prev_labels token types, we must check whether a table-question pair is the first in a sequence or not. In case it is, we can just encode it. In case it isn't, we need to encode it together with the previous table-question pair.\n",
        "\n",
        "Note that this is not the most efficient approach, because we're effectively tokenizing each table-question pair twice when applied on the entire dataset (feel free to ping me a more efficient solution)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-n9vDTD1-k9"
      },
      "source": [
        "class TableDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.df.iloc[idx]\n",
        "        table = pd.read_csv(table_csv_path + item.table_file[9:]).astype(str) # TapasTokenizer expects the table data to be text only\n",
        "        if item.position != 0:\n",
        "          # use the previous table-question pair to correctly set the prev_labels token type ids\n",
        "          previous_item = self.df.iloc[idx-1]\n",
        "          encoding = self.tokenizer(table=table, \n",
        "                                    queries=[previous_item.question, item.question], \n",
        "                                    answer_coordinates=[previous_item.answer_coordinates, item.answer_coordinates], \n",
        "                                    answer_text=[previous_item.answer_text, item.answer_text],\n",
        "                                    padding=\"max_length\",\n",
        "                                    truncation=True,\n",
        "                                    return_tensors=\"pt\"\n",
        "          )\n",
        "          # use encodings of second table-question pair in the batch\n",
        "          encoding = {key: val[-1] for key, val in encoding.items()}\n",
        "        else:\n",
        "          # this means it's the first table-question pair in a sequence\n",
        "          encoding = self.tokenizer(table=table, \n",
        "                                    queries=item.question, \n",
        "                                    answer_coordinates=item.answer_coordinates, \n",
        "                                    answer_text=item.answer_text,\n",
        "                                    padding=\"max_length\",\n",
        "                                    truncation=True,\n",
        "                                    return_tensors=\"pt\"\n",
        "          )\n",
        "          # remove the batch dimension which the tokenizer adds \n",
        "          encoding = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        return encoding\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "train_dataset = TableDataset(df=data, tokenizer=tokenizer)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=2)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4CHgnTzwfNp",
        "outputId": "1a12f95d-65bd-42c6-ea90-7036f7e66dc9"
      },
      "source": [
        "train_dataset[0][\"token_type_ids\"].shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZN1psdBy5_s",
        "outputId": "d9c03589-c589-472c-ca3d-3c0962efcfcf"
      },
      "source": [
        "train_dataset[1][\"input_ids\"].shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHAyf85k_xQt"
      },
      "source": [
        "batch = next(iter(train_dataloader))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoqySHh-_0JV",
        "outputId": "aae0335b-6140-441e-e6dc-28d5a6a102b3"
      },
      "source": [
        "batch[\"input_ids\"].shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5pjJCCT_53N",
        "outputId": "07897ebd-9fea-4ade-fa61-10f65c579ed4"
      },
      "source": [
        "batch[\"token_type_ids\"].shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 512, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVb1-H-jAEoS"
      },
      "source": [
        "Let's decode the first table-question pair:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "id": "1vfjT1JC_7zI",
        "outputId": "26c0fa5b-84ae-461e-f367-e0b8accc0c4b"
      },
      "source": [
        "tokenizer.decode(batch[\"input_ids\"][0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] where are the players from? [SEP] pick player team position school 1 ben mcdonald baltimore orioles rhp louisiana state university 2 tyler houston atlanta braves c valley hs ( las vegas, nv ) 3 roger salkeld seattle mariners rhp saugus ( ca ) hs 4 jeff jackson philadelphia phillies of simeon hs ( chicago, il ) 5 donald harris texas rangers of texas tech university 6 paul coleman saint louis cardinals of frankston ( tx ) hs 7 frank thomas chicago white sox 1b auburn university 8 earl cunningham chicago cubs of lancaster ( sc ) hs 9 kyle abbott california angels lhp long beach state university 10 charles johnson montreal expos c westwood hs ( fort pierce, fl ) 11 calvin murray cleveland indians 3b w. t. white high school ( dallas, tx ) 12 jeff juden houston astros rhp salem ( ma ) hs 13 brent mayne kansas city royals c cal state fullerton 14 steve hosey san francisco giants of fresno state university 15 kiki jones los angeles dodgers rhp hillsborough hs ( tampa, fl ) 16 greg blosser boston red sox of sarasota ( fl ) hs 17 cal eldred milwaukee brewers rhp university of iowa 18 willie greene pittsburgh pirates ss jones county hs ( gray, ga ) 19 eddie zosky toronto blue jays ss fresno state university 20 scott bryant cincinnati reds of university of texas 21 greg gohr detroit tigers rhp santa clara university 22 tom goodwin los angeles dodgers of fresno state university 23 mo vaughn boston red sox 1b seton hall university 24 alan zinter new york mets c university of arizona 25 chuck knoblauch minnesota twins 2b texas a & m university 26 scott burrell seattle mariners rhp hamden ( ct ) hs [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sujsp8o9DtsY"
      },
      "source": [
        "#first example should not have any prev_labels set\n",
        "assert batch[\"token_type_ids\"][0][:,3].sum() == 0"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIeql5vfFI6s"
      },
      "source": [
        "Let's decode the second table-question pair and verify some more:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "id": "WrNo_qMqFOzi",
        "outputId": "50f2a1c6-1e57-4e71-92ff-e950fbe4c899"
      },
      "source": [
        "tokenizer.decode(batch[\"input_ids\"][1])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] which player went to louisiana state university? [SEP] pick player team position school 1 ben mcdonald baltimore orioles rhp louisiana state university 2 tyler houston atlanta braves c valley hs ( las vegas, nv ) 3 roger salkeld seattle mariners rhp saugus ( ca ) hs 4 jeff jackson philadelphia phillies of simeon hs ( chicago, il ) 5 donald harris texas rangers of texas tech university 6 paul coleman saint louis cardinals of frankston ( tx ) hs 7 frank thomas chicago white sox 1b auburn university 8 earl cunningham chicago cubs of lancaster ( sc ) hs 9 kyle abbott california angels lhp long beach state university 10 charles johnson montreal expos c westwood hs ( fort pierce, fl ) 11 calvin murray cleveland indians 3b w. t. white high school ( dallas, tx ) 12 jeff juden houston astros rhp salem ( ma ) hs 13 brent mayne kansas city royals c cal state fullerton 14 steve hosey san francisco giants of fresno state university 15 kiki jones los angeles dodgers rhp hillsborough hs ( tampa, fl ) 16 greg blosser boston red sox of sarasota ( fl ) hs 17 cal eldred milwaukee brewers rhp university of iowa 18 willie greene pittsburgh pirates ss jones county hs ( gray, ga ) 19 eddie zosky toronto blue jays ss fresno state university 20 scott bryant cincinnati reds of university of texas 21 greg gohr detroit tigers rhp santa clara university 22 tom goodwin los angeles dodgers of fresno state university 23 mo vaughn boston red sox 1b seton hall university 24 alan zinter new york mets c university of arizona 25 chuck knoblauch minnesota twins 2b texas a & m university 26 scott burrell seattle mariners rhp hamden ( ct ) hs [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a1OToVqxNap",
        "outputId": "749cf66d-f9b2-42fe-dfe2-698d54d75af3"
      },
      "source": [
        "assert batch[\"labels\"][0].sum() == batch[\"token_type_ids\"][1][:,3].sum()\n",
        "print(batch[\"token_type_ids\"][1][:,3].sum())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(132)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4PRdYvBE1k3",
        "outputId": "a98e95ad-c93c-484e-ad56-c79b55fae3d6"
      },
      "source": [
        "for id, prev_label in zip(batch[\"input_ids\"][1], batch[\"token_type_ids\"][1][:,3]):\n",
        "  if id != 0:\n",
        "    print(tokenizer.decode([id]), prev_label.item())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] 0\n",
            "which 0\n",
            "player 0\n",
            "went 0\n",
            "to 0\n",
            "louisiana 0\n",
            "state 0\n",
            "university 0\n",
            "? 0\n",
            "[SEP] 0\n",
            "pick 0\n",
            "player 0\n",
            "team 0\n",
            "position 0\n",
            "school 0\n",
            "1 0\n",
            "ben 0\n",
            "mcdonald 0\n",
            "baltimore 0\n",
            "orioles 0\n",
            "r 0\n",
            "##hp 0\n",
            "louisiana 1\n",
            "state 1\n",
            "university 1\n",
            "2 0\n",
            "tyler 0\n",
            "houston 0\n",
            "atlanta 0\n",
            "braves 0\n",
            "c 0\n",
            "valley 1\n",
            "hs 1\n",
            "( 1\n",
            "las 1\n",
            "vegas 1\n",
            ", 1\n",
            "n 1\n",
            "##v 1\n",
            ") 1\n",
            "3 0\n",
            "roger 0\n",
            "sal 0\n",
            "##kel 0\n",
            "##d 0\n",
            "seattle 0\n",
            "mariners 0\n",
            "r 0\n",
            "##hp 0\n",
            "sa 1\n",
            "##ug 1\n",
            "##us 1\n",
            "( 1\n",
            "ca 1\n",
            ") 1\n",
            "hs 1\n",
            "4 0\n",
            "jeff 0\n",
            "jackson 0\n",
            "philadelphia 0\n",
            "phillies 0\n",
            "of 0\n",
            "simeon 1\n",
            "hs 1\n",
            "( 1\n",
            "chicago 1\n",
            ", 1\n",
            "il 1\n",
            ") 1\n",
            "5 0\n",
            "donald 0\n",
            "harris 0\n",
            "texas 0\n",
            "rangers 0\n",
            "of 0\n",
            "texas 1\n",
            "tech 1\n",
            "university 1\n",
            "6 0\n",
            "paul 0\n",
            "coleman 0\n",
            "saint 0\n",
            "louis 0\n",
            "cardinals 0\n",
            "of 0\n",
            "franks 1\n",
            "##ton 1\n",
            "( 1\n",
            "tx 1\n",
            ") 1\n",
            "hs 1\n",
            "7 0\n",
            "frank 0\n",
            "thomas 0\n",
            "chicago 0\n",
            "white 0\n",
            "sox 0\n",
            "1b 0\n",
            "auburn 1\n",
            "university 1\n",
            "8 0\n",
            "earl 0\n",
            "cunningham 0\n",
            "chicago 0\n",
            "cubs 0\n",
            "of 0\n",
            "lancaster 1\n",
            "( 1\n",
            "sc 1\n",
            ") 1\n",
            "hs 1\n",
            "9 0\n",
            "kyle 0\n",
            "abbott 0\n",
            "california 0\n",
            "angels 0\n",
            "l 0\n",
            "##hp 0\n",
            "long 1\n",
            "beach 1\n",
            "state 1\n",
            "university 1\n",
            "10 0\n",
            "charles 0\n",
            "johnson 0\n",
            "montreal 0\n",
            "expo 0\n",
            "##s 0\n",
            "c 0\n",
            "westwood 1\n",
            "hs 1\n",
            "( 1\n",
            "fort 1\n",
            "pierce 1\n",
            ", 1\n",
            "fl 1\n",
            ") 1\n",
            "11 0\n",
            "calvin 0\n",
            "murray 0\n",
            "cleveland 0\n",
            "indians 0\n",
            "3 0\n",
            "##b 0\n",
            "w 1\n",
            ". 1\n",
            "t 1\n",
            ". 1\n",
            "white 1\n",
            "high 1\n",
            "school 1\n",
            "( 1\n",
            "dallas 1\n",
            ", 1\n",
            "tx 1\n",
            ") 1\n",
            "12 0\n",
            "jeff 0\n",
            "jude 0\n",
            "##n 0\n",
            "houston 0\n",
            "astros 0\n",
            "r 0\n",
            "##hp 0\n",
            "salem 1\n",
            "( 1\n",
            "ma 1\n",
            ") 1\n",
            "hs 1\n",
            "13 0\n",
            "brent 0\n",
            "may 0\n",
            "##ne 0\n",
            "kansas 0\n",
            "city 0\n",
            "royals 0\n",
            "c 0\n",
            "cal 1\n",
            "state 1\n",
            "fuller 1\n",
            "##ton 1\n",
            "14 0\n",
            "steve 0\n",
            "hose 0\n",
            "##y 0\n",
            "san 0\n",
            "francisco 0\n",
            "giants 0\n",
            "of 0\n",
            "fresno 1\n",
            "state 1\n",
            "university 1\n",
            "15 0\n",
            "ki 0\n",
            "##ki 0\n",
            "jones 0\n",
            "los 0\n",
            "angeles 0\n",
            "dodgers 0\n",
            "r 0\n",
            "##hp 0\n",
            "hillsborough 1\n",
            "hs 1\n",
            "( 1\n",
            "tampa 1\n",
            ", 1\n",
            "fl 1\n",
            ") 1\n",
            "16 0\n",
            "greg 0\n",
            "b 0\n",
            "##los 0\n",
            "##ser 0\n",
            "boston 0\n",
            "red 0\n",
            "sox 0\n",
            "of 0\n",
            "sara 1\n",
            "##so 1\n",
            "##ta 1\n",
            "( 1\n",
            "fl 1\n",
            ") 1\n",
            "hs 1\n",
            "17 0\n",
            "cal 0\n",
            "el 0\n",
            "##dre 0\n",
            "##d 0\n",
            "milwaukee 0\n",
            "brewers 0\n",
            "r 0\n",
            "##hp 0\n",
            "university 1\n",
            "of 1\n",
            "iowa 1\n",
            "18 0\n",
            "willie 0\n",
            "greene 0\n",
            "pittsburgh 0\n",
            "pirates 0\n",
            "ss 0\n",
            "jones 1\n",
            "county 1\n",
            "hs 1\n",
            "( 1\n",
            "gray 1\n",
            ", 1\n",
            "ga 1\n",
            ") 1\n",
            "19 0\n",
            "eddie 0\n",
            "z 0\n",
            "##os 0\n",
            "##ky 0\n",
            "toronto 0\n",
            "blue 0\n",
            "jays 0\n",
            "ss 0\n",
            "fresno 1\n",
            "state 1\n",
            "university 1\n",
            "20 0\n",
            "scott 0\n",
            "bryant 0\n",
            "cincinnati 0\n",
            "reds 0\n",
            "of 0\n",
            "university 1\n",
            "of 1\n",
            "texas 1\n",
            "21 0\n",
            "greg 0\n",
            "go 0\n",
            "##hr 0\n",
            "detroit 0\n",
            "tigers 0\n",
            "r 0\n",
            "##hp 0\n",
            "santa 1\n",
            "clara 1\n",
            "university 1\n",
            "22 0\n",
            "tom 0\n",
            "goodwin 0\n",
            "los 0\n",
            "angeles 0\n",
            "dodgers 0\n",
            "of 0\n",
            "fresno 1\n",
            "state 1\n",
            "university 1\n",
            "23 0\n",
            "mo 0\n",
            "vaughn 0\n",
            "boston 0\n",
            "red 0\n",
            "sox 0\n",
            "1b 0\n",
            "seton 1\n",
            "hall 1\n",
            "university 1\n",
            "24 0\n",
            "alan 0\n",
            "z 0\n",
            "##int 0\n",
            "##er 0\n",
            "new 0\n",
            "york 0\n",
            "mets 0\n",
            "c 0\n",
            "university 1\n",
            "of 1\n",
            "arizona 1\n",
            "25 0\n",
            "chuck 0\n",
            "knob 0\n",
            "##lau 0\n",
            "##ch 0\n",
            "minnesota 0\n",
            "twins 0\n",
            "2 0\n",
            "##b 0\n",
            "texas 1\n",
            "a 1\n",
            "& 1\n",
            "m 1\n",
            "university 1\n",
            "26 0\n",
            "scott 0\n",
            "burr 0\n",
            "##ell 0\n",
            "seattle 0\n",
            "mariners 0\n",
            "r 0\n",
            "##hp 0\n",
            "ham 1\n",
            "##den 1\n",
            "( 1\n",
            "ct 1\n",
            ") 1\n",
            "hs 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAem9QnIxoKb"
      },
      "source": [
        "## Define the model\n",
        "\n",
        "Here we initialize the model with a pre-trained base and randomly initialized cell selection head, and move it to the GPU (if available).\n",
        "\n",
        "Note that the `google/tapas-base` checkpoint has (by default) an SQA configuration, so we don't need to specify any additional hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "86d91ed4d5f44e44abaed861f84c828c",
            "29599a3d9a764f7d88e615bdedf1b9a9",
            "1b22ffcc38094db0ba1ea78a95dea8a7",
            "9e8ad7e417734b5f98834c9bad0b2b32",
            "9ada6a69004a4b6d8d91d538fde2ec22",
            "29b306a71ef24fddb802a2e8997c57f5",
            "62f0caf4fdf5411b87d25c2e7688c97a",
            "9cdba32b44bd4a1e91392f51f249b7fa",
            "45cfb9e907e04e3285f245ad12b39d50",
            "d581abebc1a145889984194e1cdc8ec3",
            "c4963ef28d4f44bc98e7e13cd1d28173",
            "21e29565491c41a4b704bf9e33a19543",
            "72401569fa2846c8bb541c8cec5b3601",
            "6494bf53b28b4fedb70e188ba8e8ffef",
            "dd4a586d0dc64f0bb06fd81c9b8da781",
            "54e49747d10b4812b5aca7f8bc4c4b26"
          ]
        },
        "id": "_OsPodbiDliR",
        "outputId": "71e78644-3763-4ac0-a59a-ac1719c59661"
      },
      "source": [
        "from transformers import TapasForQuestionAnswering\n",
        "\n",
        "model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86d91ed4d5f44e44abaed861f84c828c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1432.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45cfb9e907e04e3285f245ad12b39d50",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442768791.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of TapasForQuestionAnswering were not initialized from the model checkpoint at google/tapas-base and are newly initialized: ['output_weights', 'column_output_weights', 'column_output_bias', 'output_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TapasForQuestionAnswering(\n",
              "  (tapas): TapasModel(\n",
              "    (embeddings): TapasEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(1024, 768)\n",
              "      (token_type_embeddings_0): Embedding(3, 768)\n",
              "      (token_type_embeddings_1): Embedding(256, 768)\n",
              "      (token_type_embeddings_2): Embedding(256, 768)\n",
              "      (token_type_embeddings_3): Embedding(2, 768)\n",
              "      (token_type_embeddings_4): Embedding(256, 768)\n",
              "      (token_type_embeddings_5): Embedding(256, 768)\n",
              "      (token_type_embeddings_6): Embedding(10, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.07, inplace=False)\n",
              "    )\n",
              "    (encoder): TapasEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.07, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.07, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): TapasPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.07, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtvkIFkCzdsg"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "Let's fine-tune the model in well-known PyTorch fashion:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyEZVmbdzWV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9da60a07-dfe3-438b-b824-2e729af79462"
      },
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "   print(\"Epoch:\", epoch)\n",
        "   for idx, batch in enumerate(train_dataloader):\n",
        "        # get the inputs;\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "        \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids,\n",
        "                       labels=labels)\n",
        "        loss = outputs.loss\n",
        "        print(\"Loss:\", loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Loss: 2.3279523849487305\n",
            "Loss: 2.0825817584991455\n",
            "Loss: 1.2136731147766113\n",
            "Loss: 1.5689668655395508\n",
            "Loss: 1.6408194303512573\n",
            "Loss: 2.653181552886963\n",
            "Loss: 2.0422677993774414\n",
            "Loss: 2.8373472690582275\n",
            "Loss: 2.618562698364258\n",
            "Loss: 2.574882745742798\n",
            "Loss: 2.0190718173980713\n",
            "Loss: 1.7104053497314453\n",
            "Loss: 1.8446159362792969\n",
            "Loss: 1.4145081043243408\n",
            "Epoch: 1\n",
            "Loss: 1.9239121675491333\n",
            "Loss: 0.9056147933006287\n",
            "Loss: 0.7929787635803223\n",
            "Loss: 1.3638291358947754\n",
            "Loss: 1.8447273969650269\n",
            "Loss: 1.737560510635376\n",
            "Loss: 1.6600255966186523\n",
            "Loss: 1.214841604232788\n",
            "Loss: 1.877833366394043\n",
            "Loss: 1.1238768100738525\n",
            "Loss: 1.1775801181793213\n",
            "Loss: 1.1039364337921143\n",
            "Loss: 1.3688890933990479\n",
            "Loss: 0.5591024160385132\n",
            "Epoch: 2\n",
            "Loss: 1.578884482383728\n",
            "Loss: 0.5403813123703003\n",
            "Loss: 0.43890663981437683\n",
            "Loss: 0.5364801287651062\n",
            "Loss: 0.7081422805786133\n",
            "Loss: 1.3405365943908691\n",
            "Loss: 1.0213207006454468\n",
            "Loss: 1.7228341102600098\n",
            "Loss: 1.4736838340759277\n",
            "Loss: 0.6596522331237793\n",
            "Loss: 0.491535484790802\n",
            "Loss: 0.8204508423805237\n",
            "Loss: 0.9241733551025391\n",
            "Loss: 0.39742013812065125\n",
            "Epoch: 3\n",
            "Loss: 0.8074651956558228\n",
            "Loss: 0.41197454929351807\n",
            "Loss: 0.21470907330513\n",
            "Loss: 0.4925466477870941\n",
            "Loss: 1.0673378705978394\n",
            "Loss: 0.7990034818649292\n",
            "Loss: 0.8906022310256958\n",
            "Loss: 0.7586918473243713\n",
            "Loss: 1.0095460414886475\n",
            "Loss: 0.5317187905311584\n",
            "Loss: 0.2504270076751709\n",
            "Loss: 0.5319272875785828\n",
            "Loss: 0.5988501310348511\n",
            "Loss: 0.6865168809890747\n",
            "Epoch: 4\n",
            "Loss: 1.5570335388183594\n",
            "Loss: 0.17855679988861084\n",
            "Loss: 0.11147786676883698\n",
            "Loss: 0.37335482239723206\n",
            "Loss: 0.35095876455307007\n",
            "Loss: 0.7554207444190979\n",
            "Loss: 0.5624728202819824\n",
            "Loss: 0.4735964834690094\n",
            "Loss: 1.549515724182129\n",
            "Loss: 1.2502113580703735\n",
            "Loss: 0.4868921637535095\n",
            "Loss: 0.25650444626808167\n",
            "Loss: 0.24980947375297546\n",
            "Loss: 0.18394112586975098\n",
            "Epoch: 5\n",
            "Loss: 0.2577962875366211\n",
            "Loss: 1.8943092823028564\n",
            "Loss: 0.20422644913196564\n",
            "Loss: 0.22898292541503906\n",
            "Loss: 2.97934889793396\n",
            "Loss: 0.6018719673156738\n",
            "Loss: 0.6250028610229492\n",
            "Loss: 0.6922932267189026\n",
            "Loss: 0.9675153493881226\n",
            "Loss: 0.4413134455680847\n",
            "Loss: 0.13010665774345398\n",
            "Loss: 0.4343264400959015\n",
            "Loss: 1.9350833892822266\n",
            "Loss: 0.20700182020664215\n",
            "Epoch: 6\n",
            "Loss: 0.7029200792312622\n",
            "Loss: 0.38841938972473145\n",
            "Loss: 0.14080780744552612\n",
            "Loss: 0.15042872726917267\n",
            "Loss: 0.39274826645851135\n",
            "Loss: 1.3782154321670532\n",
            "Loss: 1.1025491952896118\n",
            "Loss: 1.855236530303955\n",
            "Loss: 0.6912712454795837\n",
            "Loss: 0.6019639372825623\n",
            "Loss: 0.9471891522407532\n",
            "Loss: 0.3142096996307373\n",
            "Loss: 0.5672016143798828\n",
            "Loss: 0.06744787096977234\n",
            "Epoch: 7\n",
            "Loss: 0.7237601280212402\n",
            "Loss: 0.181310772895813\n",
            "Loss: 0.06591715663671494\n",
            "Loss: 0.33117759227752686\n",
            "Loss: 0.6560579538345337\n",
            "Loss: 0.4589031934738159\n",
            "Loss: 0.43325507640838623\n",
            "Loss: 0.5004587173461914\n",
            "Loss: 0.9699493646621704\n",
            "Loss: 0.6237034201622009\n",
            "Loss: 0.15100742876529694\n",
            "Loss: 0.12731881439685822\n",
            "Loss: 0.16499243676662445\n",
            "Loss: 0.037740036845207214\n",
            "Epoch: 8\n",
            "Loss: 0.5272416472434998\n",
            "Loss: 0.09664261341094971\n",
            "Loss: 0.03154757246375084\n",
            "Loss: 0.05289696902036667\n",
            "Loss: 0.17900803685188293\n",
            "Loss: 0.4376428425312042\n",
            "Loss: 0.06300805509090424\n",
            "Loss: 1.3086053133010864\n",
            "Loss: 0.18170854449272156\n",
            "Loss: 2.668813943862915\n",
            "Loss: 0.06832332909107208\n",
            "Loss: 0.5659621357917786\n",
            "Loss: 0.07046064734458923\n",
            "Loss: 0.2901937663555145\n",
            "Epoch: 9\n",
            "Loss: 0.4235270321369171\n",
            "Loss: 0.06715531647205353\n",
            "Loss: 0.03599444776773453\n",
            "Loss: 0.05650928616523743\n",
            "Loss: 0.19962283968925476\n",
            "Loss: 0.277540385723114\n",
            "Loss: 0.13070760667324066\n",
            "Loss: 0.6112580895423889\n",
            "Loss: 0.8232967853546143\n",
            "Loss: 0.8626859784126282\n",
            "Loss: 0.1375809758901596\n",
            "Loss: 0.3686489164829254\n",
            "Loss: 0.069179967045784\n",
            "Loss: 0.03410390391945839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmugNHCN20QF"
      },
      "source": [
        "## Inference\n",
        "\n",
        "As SQA is a bit different due to its conversational nature, we need to run every training example of the a batch one by one through the model (sequentially), overwriting the `prev_labels` token types (which were created by the tokenizer) by the answer predicted by the model. It is based on the [following code](https://github.com/google-research/tapas/blob/f458b6624b8aa75961a0ab78e9847355022940d3/tapas/experiments/prediction_utils.py#L92) from the official implementation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhJwoaSy26PD"
      },
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "\n",
        "def compute_prediction_sequence(model, data, device):\n",
        "  \"\"\"Computes predictions using model's answers to the previous questions.\"\"\"\n",
        "  \n",
        "  # prepare data\n",
        "  input_ids = data[\"input_ids\"].to(device)\n",
        "  attention_mask = data[\"attention_mask\"].to(device)\n",
        "  token_type_ids = data[\"token_type_ids\"].to(device)\n",
        "\n",
        "  all_logits = []\n",
        "  prev_answers = None\n",
        "\n",
        "  num_batch = data[\"input_ids\"].shape[0]\n",
        "  \n",
        "  for idx in range(num_batch):\n",
        "    \n",
        "    if prev_answers is not None:\n",
        "        coords_to_answer = prev_answers[idx]\n",
        "        # Next, set the label ids predicted by the model\n",
        "        prev_label_ids_example = token_type_ids_example[:,3] # shape (seq_len,)\n",
        "        model_label_ids = np.zeros_like(prev_label_ids_example.cpu().numpy()) # shape (seq_len,)\n",
        "\n",
        "        # for each token in the sequence:\n",
        "        token_type_ids_example = token_type_ids[idx] # shape (seq_len, 7)\n",
        "        for i in range(model_label_ids.shape[0]):\n",
        "          segment_id = token_type_ids_example[:,0].tolist()[i]\n",
        "          col_id = token_type_ids_example[:,1].tolist()[i] - 1\n",
        "          row_id = token_type_ids_example[:,2].tolist()[i] - 1\n",
        "          if row_id >= 0 and col_id >= 0 and segment_id == 1:\n",
        "            model_label_ids[i] = int(coords_to_answer[(col_id, row_id)])\n",
        "\n",
        "        # set the prev label ids of the example (shape (1, seq_len) )\n",
        "        token_type_ids_example[:,3] = torch.from_numpy(model_label_ids).type(torch.long).to(device)   \n",
        "\n",
        "    prev_answers = {}\n",
        "    # get the example\n",
        "    input_ids_example = input_ids[idx] # shape (seq_len,)\n",
        "    attention_mask_example = attention_mask[idx] # shape (seq_len,)\n",
        "    token_type_ids_example = token_type_ids[idx] # shape (seq_len, 7)\n",
        "    # forward pass to obtain the logits\n",
        "    outputs = model(input_ids=input_ids_example.unsqueeze(0), \n",
        "                    attention_mask=attention_mask_example.unsqueeze(0), \n",
        "                    token_type_ids=token_type_ids_example.unsqueeze(0))\n",
        "    logits = outputs.logits\n",
        "    all_logits.append(logits)\n",
        "\n",
        "    # convert logits to probabilities (which are of shape (1, seq_len))\n",
        "    dist_per_token = torch.distributions.Bernoulli(logits=logits)\n",
        "    probabilities = dist_per_token.probs * attention_mask_example.type(torch.float32).to(dist_per_token.probs.device) \n",
        "\n",
        "    # Compute average probability per cell, aggregating over tokens.\n",
        "    # Dictionary maps coordinates to a list of one or more probabilities\n",
        "    coords_to_probs = collections.defaultdict(list)\n",
        "    prev_answers = {}\n",
        "    for i, p in enumerate(probabilities.squeeze().tolist()):\n",
        "      segment_id = token_type_ids_example[:,0].tolist()[i]\n",
        "      col = token_type_ids_example[:,1].tolist()[i] - 1\n",
        "      row = token_type_ids_example[:,2].tolist()[i] - 1\n",
        "      if col >= 0 and row >= 0 and segment_id == 1:\n",
        "        coords_to_probs[(col, row)].append(p)\n",
        "\n",
        "    # Next, map cell coordinates to 1 or 0 (depending on whether the mean prob of all cell tokens is > 0.5)\n",
        "    coords_to_answer = {}\n",
        "    for key in coords_to_probs:\n",
        "      coords_to_answer[key] = np.array(coords_to_probs[key]).mean() > 0.5\n",
        "    prev_answers[idx+1] = coords_to_answer\n",
        "    \n",
        "  logits_batch = torch.cat(tuple(all_logits), 0)\n",
        "  \n",
        "  return logits_batch"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jflxDE_BfVg9"
      },
      "source": [
        "data = {'Actors': [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \n",
        "        'Age': [\"56\", \"45\", \"59\"],\n",
        "        'Number of movies': [\"87\", \"53\", \"69\"],\n",
        "        'Date of birth': [\"7 february 1967\", \"10 june 1996\", \"28 november 1967\"]}\n",
        "queries = [\"How many movies has George Clooney played in?\", \"How old is he?\", \"What's his date of birth?\"]\n",
        "\n",
        "table = pd.DataFrame.from_dict(data)\n",
        "\n",
        "inputs = tokenizer(table=table, queries=queries, padding='max_length', return_tensors=\"pt\")\n",
        "logits = compute_prediction_sequence(model, inputs, device)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_a_Y-rDq__o"
      },
      "source": [
        "Finally, we can use the handy `convert_logits_to_predictions` function of `TapasTokenizer` to convert the logits into predicted coordinates, and print out the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fAcNOVsqoVD"
      },
      "source": [
        "predicted_answer_coordinates, = tokenizer.convert_logits_to_predictions(inputs, logits.cpu().detach())"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP4AHMxFujhV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "80027e5e-33cf-435e-b570-17c6a8a2df56"
      },
      "source": [
        "# handy helper function in case inference on Pandas dataframe\n",
        "answers = []\n",
        "for coordinates in predicted_answer_coordinates:\n",
        "  if len(coordinates) == 1:\n",
        "    # only a single cell:\n",
        "    answers.append(table.iat[coordinates[0]])\n",
        "  else:\n",
        "    # multiple cells\n",
        "    cell_values = []\n",
        "    for coordinate in coordinates:\n",
        "      cell_values.append(table.iat[coordinate])\n",
        "    answers.append(\", \".join(cell_values))\n",
        "\n",
        "display(table)\n",
        "print(\"\")\n",
        "for query, answer in zip(queries, answers):\n",
        "  print(query)\n",
        "  print(\"Predicted answer: \" + answer)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actors</th>\n",
              "      <th>Age</th>\n",
              "      <th>Number of movies</th>\n",
              "      <th>Date of birth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Brad Pitt</td>\n",
              "      <td>56</td>\n",
              "      <td>87</td>\n",
              "      <td>7 february 1967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Leonardo Di Caprio</td>\n",
              "      <td>45</td>\n",
              "      <td>53</td>\n",
              "      <td>10 june 1996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>George Clooney</td>\n",
              "      <td>59</td>\n",
              "      <td>69</td>\n",
              "      <td>28 november 1967</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Actors Age Number of movies     Date of birth\n",
              "0           Brad Pitt  56               87   7 february 1967\n",
              "1  Leonardo Di Caprio  45               53      10 june 1996\n",
              "2      George Clooney  59               69  28 november 1967"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "How many movies has George Clooney played in?\n",
            "Predicted answer: \n",
            "How old is he?\n",
            "Predicted answer: 56, 45, 59\n",
            "What's his date of birth?\n",
            "Predicted answer: Brad Pitt, Leonardo Di Caprio, George Clooney\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L0KBaPjG7uj"
      },
      "source": [
        "Note that the results here are not correct, that's obvious since we only trained on 28 examples and tested it on an entire different example. In reality, you should train on the entire dataset. The result of this is the `google/tapas-base-finetuned-sqa` checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFLPRH1VgURN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}