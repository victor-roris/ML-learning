{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dimensionality Reduction - Principal Component Analysis (PCA).ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNRJza9FYHmnqirJV+3bZBt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor-roris/ML-learning/blob/master/ML-Mathematics/Dimensionality_Reduction_Principal_Component_Analysis_(PCA).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SglRHpX6UQck"
      },
      "source": [
        "# Principal Component Analysis\n",
        "\n",
        "Original source: [link](https://towardsdatascience.com/principal-component-analysis-for-dimensionality-reduction-115a3d157bad)\n",
        "\n",
        "Dimensionality reduction is way to reduce the complexity of a model and avoid overfitting. There are two main categories of dimensionality reduction:\n",
        "\n",
        " - feature selection: we select a subset of the original features\n",
        " - feature extraction: we derive information from the feature set to construct a new feature subspace.\n",
        "\n",
        "**Principal Component Analysis (PCA)** is an unsupervised linear transformation technique that is prominently used for **feature extraction** and dimensionality reduction.\n",
        "\n",
        "PCA helps us to identify patterns in data based on the correlation between features. In a nutshell, PCA aims to find the directions of maximum variance in high-dimensional data and projects it onto a new subspace with equal or fewer dimensions than the original one.\n",
        "\n",
        "The orthogonal axes (principal components) of the new subspace can be interpreted as the directions of maximum variance given the constraint that the new feature axes are orthogonal to each other,\n",
        "\n",
        "In PCA dimensionality reduction, we construct a `d x k`–dimensional transformation matrix W that allows us to map a sample vector `x` onto a new `k`–dimensional feature subspace that has fewer dimensions than the original `d`–dimensional feature space\n",
        "\n",
        "![equation1](https://miro.medium.com/max/182/1*ytEHO-Wjos_ugY2LffXEyg.png)\n",
        "\n",
        "As a result of transforming the original d-dimensional data onto this new k-dimensional subspace (typically k ≪ d), the first principal component will have the largest possible variance, and all consequent principal components will have the largest variance given the constraint that these components are uncorrelated (orthogonal) to the other principal components — even if the input features are correlated, the resulting principal components will be mutually orthogonal (uncorrelated).\n",
        "\n",
        "Note that the PCA directions are highly sensitive to data scaling, and we need to standardize the features prior to PCA\n",
        "\n",
        "PCA approach:\n",
        " 1. Standardize the d-dimensional dataset.\n",
        " 2. Construct the covariance matrix.\n",
        " 3. Decompose the covariance matrix into its eigenvectors and eigenvalues.\n",
        " 4. Sort the eigenvalues by decreasing order to rank the corresponding eigenvectors.\n",
        " 5. Select k eigenvectors which correspond to the k largest eigenvalues, where k is the dimensionality of the new feature subspace (k ≤ d).\n",
        " 6. Construct a projection matrix W from the “top” k eigenvectors.\n",
        " 7. Transform the d-dimensional input dataset X using the projection matrix W to obtain the new k-dimensional feature subspace.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rIhALggWtUl"
      },
      "source": [
        "## PCA Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtcKSApD3a8q"
      },
      "source": [
        "k = 2 # Dimension of the new feature subspace"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaVKHaB-XVzG"
      },
      "source": [
        "### Load input data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "kn0lvtZdXDv-",
        "outputId": "2343e2db-f010-4ecb-e5f1-c6a27c103f3c"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/'\n",
        "                      'machine-learning-databases/wine/wine.data',\n",
        "                      header=None)\n",
        "\n",
        "print(f\"Number of entries : {len(df_wine)}\")\n",
        "print(f\"Number of columns : {len(df_wine.columns)}\")\n",
        "df_wine.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of entries : 178\n",
            "Number of columns : 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0      1     2     3     4    5   ...    8     9     10    11    12    13\n",
              "0   1  14.23  1.71  2.43  15.6  127  ...  0.28  2.29  5.64  1.04  3.92  1065\n",
              "1   1  13.20  1.78  2.14  11.2  100  ...  0.26  1.28  4.38  1.05  3.40  1050\n",
              "2   1  13.16  2.36  2.67  18.6  101  ...  0.30  2.81  5.68  1.03  3.17  1185\n",
              "3   1  14.37  1.95  2.50  16.8  113  ...  0.24  2.18  7.80  0.86  3.45  1480\n",
              "4   1  13.24  2.59  2.87  21.0  118  ...  0.39  1.82  4.32  1.04  2.93   735\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4i5PrqeXcuB"
      },
      "source": [
        "Split into training and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8SmyMTyXLMw"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# split into training and testing sets\n",
        "X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3,\n",
        "    stratify=y, random_state=0\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o328w3QX3Pv",
        "outputId": "f8dfd485-f394-4cab-af66-f8b1d83c61fc"
      },
      "source": [
        "print(f\"Number of entries in the training dataset : {X_train.shape[0]}\")\n",
        "print(f\"Number of entries in the testing dataset : {X_test.shape[0]}\")\n",
        "\n",
        "print(f\"Dimensionality of each input vector {X_train.shape[1]}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of entries in the training dataset : 124\n",
            "Number of entries in the testing dataset : 54\n",
            "Dimensionality of each input vector 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL2TOBXDXrh-"
      },
      "source": [
        "## Standardize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZdk9IyUXhGy"
      },
      "source": [
        "# standardize the features\n",
        "sc = StandardScaler()\n",
        "X_train_std = sc.fit_transform(X_train)\n",
        "X_test_std = sc.transform(X_test)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b89Et6GzY739"
      },
      "source": [
        "## Construct the covariance matrix\n",
        "\n",
        "covariance between two features x<sub>j</sub> and x<sub>t</sub> (I changed the index k of the image by t because k term is the final dimension of th PCA too)\n",
        "\n",
        "![equation2](https://miro.medium.com/max/195/1*zsJQIL5ZnHRxxqxz0OxntQ.png)\n",
        "\n",
        "Where, μ<sub>j</sub> and μ<sub>t</sub> are the sample means of features j and k, respectively.\n",
        "\n",
        "A positive covariance between two features indicates that the features increase or decrease together, whereas a negative covariance indicates that the features vary in opposite directions. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PISGXZebyoe",
        "outputId": "99b3193d-28e9-4c12-9c09-dad9cef9e3f5"
      },
      "source": [
        "# Feature Index\n",
        "j = 0\n",
        "t = 1\n",
        "\n",
        "# Assert dimensionality\n",
        "assert j < X_train_std.shape[1], \"There arent enought features\"\n",
        "assert t < X_train_std.shape[1], \"There arent enought features\"\n",
        "\n",
        "# Feature values\n",
        "j_feature_std_values = X_train_std[:, j]\n",
        "t_feature_std_values = X_train_std[:, t]\n",
        "\n",
        "# Sample means\n",
        "nu_j = sum(j_feature_std_values)/len(j_feature_std_values)\n",
        "nu_t = sum(t_feature_std_values)/len(t_feature_std_values)\n",
        "\n",
        "# Covariance\n",
        "n = len(X_train_std)\n",
        "sigma_jt = sum([(j_feature_std_values[i]-nu_j)*(k_feature_std_values[i]-nu_t) for i in range(n)])/n\n",
        "\n",
        "print(f\"Covariance between the features {j}-{t} = {sigma_jt}\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Covariance between the features 0-1 = 0.06655446263030922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOdkdR9pdwSu"
      },
      "source": [
        "The covariance matrix of three features can then be written as follows:\n",
        "\n",
        "![covariance matrix](https://miro.medium.com/max/123/1*vyx57OmdL9HXraN-AkBSEw.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAZ7ZcDlXyXV",
        "outputId": "05dc9833-6b01-4c39-af4b-b14efd6d1094"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "cov_mat = np.cov(X_train_std.T)\n",
        "\n",
        "print(f\"Dimensionality of the covariance matrix: {cov_mat.shape}\")\n",
        "\n",
        "print(\"Covariance of the first feature with the rest of features:\")\n",
        "cov_mat[0,:]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensionality of the covariance matrix: (13, 13)\n",
            "Covariance of the first feature with the rest of features:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.00813008,  0.06709556,  0.17405351, -0.35439069,  0.26374703,\n",
              "        0.29079481,  0.21835807, -0.08111974,  0.10436705,  0.54282846,\n",
              "        0.05893536, -0.01797029,  0.6415292 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dISVUx-CeHei"
      },
      "source": [
        "## Decompose the covariance matrix into its eigenvectors and eigenvalues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqjW6M3XbQQW"
      },
      "source": [
        "The eigenvectors of the covariance matrix represent the principal components (the directions of maximum variance), whereas the corresponding eigenvalues will define their magnitude. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj-99EaQYfrY",
        "outputId": "5eb84507-a688-47ac-decb-46910ef3794f"
      },
      "source": [
        "eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)\n",
        "\n",
        "print(f\"Shape eigen_vals vector (one val by feature) : {eigen_vals.shape}\")\n",
        "print(f\"Shape eigen_vecs matrix (n_feature values by feature): {eigen_vecs.shape}\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape eigen_vals vector (one val by feature) : (13,)\n",
            "Shape eigen_vecs matrix (n_feature values by feature): (13, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H_CVvpJzXxH"
      },
      "source": [
        "\n",
        "An eigenvector v satisfies the following condition:\n",
        "\n",
        "![eigenvector](https://miro.medium.com/max/53/1*noDBksvur0Y3mi0zeyy9dg.png)\n",
        "\n",
        "Here, λ is a scalar: the eigenvalue."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6D41DEazXEt"
      },
      "source": [
        "# Check this condition (how?)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OZwkDpCztqR"
      },
      "source": [
        "## Sort the eigenvalues by decreasing order to rank the corresponding eigenvectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyuqYKm41f3u"
      },
      "source": [
        "\n",
        "### Total and Explained Variance\n",
        "Since we want to reduce the dimensionality of our dataset by compressing it onto a new feature subspace, we only select the subset of the eigenvectors (principal components) that contains most of the information (variance). The eigenvalues define the magnitude of the eigenvectors, so we have to sort the eigenvalues by decreasing magnitude; we are interested in the top k eigenvectors based on the values of their corresponding eigenvalues.\n",
        "\n",
        "Before we collect those k most informative eigenvectors, let’s plot the variance explained ratios of the eigenvalues.\n",
        "\n",
        "The variance explained ratio of an eigenvalue λ<sbu>j</sub> is:\n",
        "\n",
        "![acu variance](https://miro.medium.com/max/49/1*e3Ud73T1QZaock4MBb-lMw.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yy4LuEV04hQ",
        "outputId": "84525681-111a-4a2d-c711-ad700c4996ab"
      },
      "source": [
        "# calculate cumulative sum of explained variances\n",
        "tot = sum(eigen_vals)\n",
        "var_exp = [(i / tot) for i in sorted(eigen_vals, reverse=True)]\n",
        "\n",
        "var_exp"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3695146859960764,\n",
              " 0.18434927059884174,\n",
              " 0.1181515909459698,\n",
              " 0.0733425176378546,\n",
              " 0.06422107821731668,\n",
              " 0.05051724484907658,\n",
              " 0.03954653891241442,\n",
              " 0.026439183169220035,\n",
              " 0.02389319259185293,\n",
              " 0.016296137737251012,\n",
              " 0.013800211221948416,\n",
              " 0.011722262443085961,\n",
              " 0.008206085679091387]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fr9ymME1GPN"
      },
      "source": [
        "Using the NumPy cumsum function, we can then calculate the cumulative sum of explained variances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8FTMkyr1DE8",
        "outputId": "bfa7a956-d124-49e1-997a-49815e8ba19f"
      },
      "source": [
        "cum_var_exp = np.cumsum(var_exp) # cumulative sum of explained variances\n",
        "\n",
        "cum_var_exp"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.36951469, 0.55386396, 0.67201555, 0.74535807, 0.80957914,\n",
              "       0.86009639, 0.89964293, 0.92608211, 0.9499753 , 0.96627144,\n",
              "       0.98007165, 0.99179391, 1.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgBM0qaM1WDk"
      },
      "source": [
        "Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "vV6-h4-eiErf",
        "outputId": "d98184c1-9106-4e56-db1a-54d5bf589022"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot explained variances\n",
        "plt.bar(range(1,14), var_exp, alpha=0.5,\n",
        "        align='center', label='individual explained variance')\n",
        "plt.step(range(1,14), cum_var_exp, where='mid',\n",
        "         label='cumulative explained variance')\n",
        "plt.ylabel('Explained variance ratio')\n",
        "plt.xlabel('Principal component index')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxI8pzsE1SW2"
      },
      "source": [
        "The resulting plot indicates that the first principal component alone accounts for approximately 40% of the variance. Also, we can see that the first two principal components combined explain almost 60% of the variance in the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Hf8LH-C1lSR"
      },
      "source": [
        "### Sort\n",
        "\n",
        "Sort the eigenpairs by decreasing order of the eigenvalues:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL1Sl3uJiHX-"
      },
      "source": [
        "# Make a list of (eigenvalue, eigenvector) tuples\n",
        "eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:, i]) for i in range(len(eigen_vals))]\n",
        "\n",
        "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
        "eigen_pairs.sort(key=lambda k: k[0], reverse=True)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zn6q0PWpwviC",
        "outputId": "7500d37f-6ea3-4690-c35b-e8aa45b87eec"
      },
      "source": [
        "print(f\"Higher eigenvalue : {eigen_pairs[0][0]}\")\n",
        "print(f\" -> Associated eigenverctor (1x{len(eigen_pairs[0][1])}) : {eigen_pairs[0][1]}\")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Higher eigenvalue : 4.842745315655893\n",
            " -> Associated eigenverctor (1x13) : [-0.13724218  0.24724326 -0.02545159  0.20694508 -0.15436582 -0.39376952\n",
            " -0.41735106  0.30572896 -0.30668347  0.07554066 -0.32613263 -0.36861022\n",
            " -0.29669651]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VuqDdSg2fu9"
      },
      "source": [
        "## Select k eigenvectors which correspond to the k largest eigenvalues, where k is the dimensionality of the new feature subspace (k ≤ d)\n",
        "\n",
        "Next, we collect the k eigenvectors that correspond to the k largest eigenvalues. That means the k stronger directions (axes in the space)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PusAdW45rF4",
        "outputId": "7609e70b-7f4f-4c2e-d062-4da2086bf82d"
      },
      "source": [
        "print(f\"New dimensionality k = {k}\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New dimensionality k = 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_SPATIY30g3",
        "outputId": "a97b84d2-8180-48f7-a5b3-74f7551e4736"
      },
      "source": [
        "k_eigenvec = [eigen_pairs[i][1][:, np.newaxis] for i in range(k)]\n",
        "\n",
        "print(f\"Number of considered eigen_vecs to the new subspace k= {len(k_eigenvec)}\")\n",
        "print(f\"Number of entries by eing_vecs (same as original dimensionality) = {len(k_eigenvec[0])}\")"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of considered eigen_vecs to the new subspace k= 2\n",
            "Number of entries by eing_vecs (same as original dimensionality) = 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.13724218],\n",
              "        [ 0.24724326],\n",
              "        [-0.02545159],\n",
              "        [ 0.20694508],\n",
              "        [-0.15436582],\n",
              "        [-0.39376952],\n",
              "        [-0.41735106],\n",
              "        [ 0.30572896],\n",
              "        [-0.30668347],\n",
              "        [ 0.07554066],\n",
              "        [-0.32613263],\n",
              "        [-0.36861022],\n",
              "        [-0.29669651]]), array([[ 0.50303478],\n",
              "        [ 0.16487119],\n",
              "        [ 0.24456476],\n",
              "        [-0.11352904],\n",
              "        [ 0.28974518],\n",
              "        [ 0.05080104],\n",
              "        [-0.02287338],\n",
              "        [ 0.09048885],\n",
              "        [ 0.00835233],\n",
              "        [ 0.54977581],\n",
              "        [-0.20716433],\n",
              "        [-0.24902536],\n",
              "        [ 0.38022942]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMvM51PsSImv"
      },
      "source": [
        "## Construct a projection matrix W from the “top” k eigenvectors\n",
        "\n",
        "With the k stronger eigen vectors we generate a projection matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwUkF9PvSMKU",
        "outputId": "1f52cd99-f295-425c-9498-b6ff9b4195f6"
      },
      "source": [
        "w = np.hstack(k_eigenvec)\n",
        "print(f'Matrix W {w.shape}:\\n', w)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matrix W (13, 2):\n",
            " [[-0.13724218  0.50303478]\n",
            " [ 0.24724326  0.16487119]\n",
            " [-0.02545159  0.24456476]\n",
            " [ 0.20694508 -0.11352904]\n",
            " [-0.15436582  0.28974518]\n",
            " [-0.39376952  0.05080104]\n",
            " [-0.41735106 -0.02287338]\n",
            " [ 0.30572896  0.09048885]\n",
            " [-0.30668347  0.00835233]\n",
            " [ 0.07554066  0.54977581]\n",
            " [-0.32613263 -0.20716433]\n",
            " [-0.36861022 -0.24902536]\n",
            " [-0.29669651  0.38022942]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anMXmoZMUfrc"
      },
      "source": [
        "## Transform the d-dimensional input dataset X using the projection matrix W to obtain the new k-dimensional feature subspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9suoLsCj5mD7"
      },
      "source": [
        "By executing the preceding code, we have created a 13 x k -dimensional projection matrix W from the top k eigenvectors.\n",
        "\n",
        "Using the projection matrix, we can now transform a sample x (represented as a 1 x 13-dimensional row vector) onto the PCA subspace (the principal components one and two) obtaining x′, now a two-dimensional sample vector consisting of two new features:\n",
        "\n",
        "![vector transf](https://miro.medium.com/max/59/1*nuYZrTF8trabAfJq-3wVcA.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMHY2Ff1yKiN",
        "outputId": "25422ec5-2330-451e-85b8-75e680e4d8d7"
      },
      "source": [
        "pos = 0\n",
        "\n",
        "x = X_train_std[pos]\n",
        "\n",
        "print(f'Example x from the {pos} entry : {x}')\n",
        "\n",
        "# Transform the x to the new PCA subspace\n",
        "x_new = x.dot(w)\n",
        "\n",
        "print(f\"Representation of x in the new {k}-d subspace : {x_new}\")"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example x from the 0 entry : [ 0.71225893  2.22048673 -0.13025864  0.05962872 -0.50432733 -0.52831584\n",
            " -1.24000033  0.84118003 -1.05215112 -0.29218864 -0.20017028 -0.82164144\n",
            " -0.62946362]\n",
            "Representation of x in the new 2-d subspace : [2.38299011 0.45458499]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3M1K7PaUsbs"
      },
      "source": [
        "Similarly, we can transform all the original dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "offfRJPAQpUU",
        "outputId": "14af4060-e3df-4876-f9ea-d6dd8d0c3e14"
      },
      "source": [
        "X_train_pca = X_train_std.dot(w)\n",
        "\n",
        "print(\"New representation of the 10 first examples\")\n",
        "X_train_pca[0:10]"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New representation of the 10 first examples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.38299011,  0.45458499],\n",
              "       [-1.96578183,  1.65376939],\n",
              "       [-2.53907598,  1.02909066],\n",
              "       [-1.43010776,  0.6024011 ],\n",
              "       [ 3.14147227,  0.66214979],\n",
              "       [ 0.50253552, -2.08907131],\n",
              "       [ 0.04867722, -2.27536044],\n",
              "       [ 2.47888989, -0.08603318],\n",
              "       [ 2.01900259, -1.3538719 ],\n",
              "       [ 0.75156583, -2.55367947]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ7KD2BP3qWD"
      },
      "source": [
        "## Visualization\n",
        "\n",
        "If the k selected we can represent it in a 2D plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "0A1NkyQSyQsH",
        "outputId": "f5e7f50e-a318-46e1-9054-d7308782cbe7"
      },
      "source": [
        "if k == 2:\n",
        "  colors = ['r', 'b', 'g']\n",
        "  markers = ['s', 'x', 'o']\n",
        "  for l, c, m in zip(np.unique(y_train), colors, markers):\n",
        "      plt.scatter(X_train_pca[y_train==l, 0], \n",
        "                  X_train_pca[y_train==l, 1], \n",
        "                  c=c, label=l, marker=m) \n",
        "  plt.xlabel('PC 1')\n",
        "  plt.ylabel('PC 2')\n",
        "  plt.legend(loc='lower left')\n",
        "  plt.show()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeJMGfELVYDB"
      },
      "source": [
        "As we can see in the resulting plot, the data is more spread along the x-axis — the first principal component — than the second principal component (y-axis), which is consistent with the explained variance ratio plot that we created previously. However, we can intuitively see that a linear classifier will likely be able to separate the classes well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GOb-nvaVNVq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}