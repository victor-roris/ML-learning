{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DirectRanker (Fails - TF incompatibilites).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPNrT6Q2tQB/VzikStS76FR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor-roris/ML-learning/blob/master/Ranking/DirectRanker_(Fails_TF_incompatibilites).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPHI4lMAypPV"
      },
      "source": [
        "# DirectRanker\n",
        "\n",
        " - [GitHub](https://github.com/kramerlab/direct-ranker)\n",
        " - [Paper](https://arxiv.org/pdf/1909.02768v1.pdf)\n",
        "\n",
        "Pairwise learning to rank approach based on a neural net, called DirectRanker, that generalizes the RankNet architecture.\n",
        "\n",
        "**NOTE**: I wasn't able to run the code. I think it can be a problem with the dataset I used and tensorflow incompatibilities. Colab use the tf v2 but if I change to v1 it fails too. I suppose they use a very specific version but they don't provide it.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtoOOv0Y0BTk"
      },
      "source": [
        "## Installation\n",
        "\n",
        "The project provided is only code, no library. This code `import`s internal packages using the project name: `supplementary_code_direct_ranker`. \n",
        "\n",
        "My strategy is the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI15XecFdc3I",
        "outputId": "2f5a1b2e-40ad-439b-b5aa-fe2eb3380268"
      },
      "source": [
        "!git clone https://github.com/kramerlab/direct-ranker.git\n",
        "!mv direct-ranker supplementary_code_direct_ranker"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'direct-ranker'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Total 16 (delta 0), reused 0 (delta 0), pack-reused 16\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_F_xAbMmokf"
      },
      "source": [
        "# some_file.py\n",
        "import sys\n",
        "# insert at 1, 0 is the script path (or '' in REPL)\n",
        "sys.path.insert(1, '/contents/supplementary_code_direct_ranker')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKAq-1hj0w2Z"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk9GSbb7dY4Q"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V7meEQV2vDA"
      },
      "source": [
        "Imports fail in the DirectRanker code because tensorflow api. The importantion can work if you use the tensorflow version 1. But then it fails again because new features. I suppose they are using a very specific version, but they not provide it. \n",
        "\n",
        "To change tensorflow version, modify the import in the corresponding files:\n",
        "```python\n",
        "# import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3CTyO-h2vLd"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from supplementary_code_direct_ranker.DirectRanker import directRanker\n",
        "from supplementary_code_direct_ranker.helpers import readData, nDCGScorer_cls, MAP_cls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb45Av_G03Qr"
      },
      "source": [
        "## Load dataset\n",
        "\n",
        "I use the `msrank` dataset. The proposed dataset is difficult to manage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YhnIW-6RXOl"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j-F6rATQLa8"
      },
      "source": [
        "from catboost.datasets import msrank_10k\n",
        "train_df, test_df = msrank_10k()\n",
        "\n",
        "X_train = train_df.drop([0, 1], axis=1).values\n",
        "y_train = train_df[0].values\n",
        "queries_train = train_df[1].values\n",
        "\n",
        "X_test = test_df.drop([0, 1], axis=1).values\n",
        "y_test = test_df[0].values\n",
        "queries_test = test_df[1].values"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SesEsjyr1xJp"
      },
      "source": [
        "## Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f16cVgroeDSE"
      },
      "source": [
        "def lambda_cost(nn, y0):\n",
        "    return tf.reduce_mean(tf.log(1+tf.exp(nn))-nn)\n",
        "\n",
        "\n",
        "# Load directRanker, train, and test\n",
        "dr = directRanker(\n",
        "    feature_activation=tf.nn.tanh,\n",
        "    ranking_activation=tf.nn.tanh,\n",
        "    # max_steps=10000,\n",
        "    # For debugging\n",
        "    #cost=lambda_cost,\n",
        "    max_steps=10000,\n",
        "    print_step=500,\n",
        "    start_batch_size=3,\n",
        "    end_batch_size=5,\n",
        "    start_qids=20,\n",
        "    end_qids=100,\n",
        "    feature_bias=True,\n",
        "    hidden_layers=[100, 50, 5]\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpNeo_l610Yd"
      },
      "source": [
        "## Train model\n",
        "\n",
        "If we change the tf version, then we have problems with the data. Can be a problem with the dataset I use?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmiQMQN5Q45l"
      },
      "source": [
        "dr.fit(X_train, y_train, ranking=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thGJ2-o713WY"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE0gAT7-gA5Q"
      },
      "source": [
        "nDCGScorer_cls(dr, X_test, y_test, at=10)\n",
        "MAP_cls(dr, x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}