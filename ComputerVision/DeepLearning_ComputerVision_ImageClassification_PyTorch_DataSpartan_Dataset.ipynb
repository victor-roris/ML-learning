{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning_ComputerVision_ImageClassification_PyTorch_DataSpartan_Dataset.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMg2Uyk4WCCkCIE4wlUnwCq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor-roris/ML-learning/blob/master/ComputerVision/DeepLearning_ComputerVision_ImageClassification_PyTorch_DataSpartan_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRZ6qTP9TXZ8",
        "colab_type": "text"
      },
      "source": [
        "# MultiLabel Image Classification \n",
        "\n",
        "In this notebook we generate a model in `pytorch` to try to classify images of figure (from a **non public dataset**).\n",
        "\n",
        "Adapted from [link](https://medium.com/@thevatsalsaglani/multi-class-image-classification-using-cnn-over-pytorch-and-the-basics-of-cnn-fdf425a11dc0) and [link](https://github.com/vatsalsaglani/ApparelClassifier/blob/master/train.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Oz90PME-F07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing modules \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import shutil\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import lr_scheduler\n",
        "from torch import optim\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GelPUuqgwCk3",
        "colab_type": "text"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO6pXsMZwFW_",
        "colab_type": "text"
      },
      "source": [
        "### Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6ipgwBtv3P_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "5f028f24-7b7f-4504-cfac-b868677053ee"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q4osxxRwKVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_folderpath = \"/content/input\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMcWifISwR3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if os.path.isdir(dataset_folderpath):\n",
        "  !rm -R {dataset_folderpath}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_Da43YvwT5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "def mkdir(sfolderpath):\n",
        "  folderpath = Path(sfolderpath)\n",
        "  folderpath.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "mkdir(dataset_folderpath)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GWRHJuUwV7x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0b87a8c6-ccc9-4413-a2c7-4d5448fb2d68"
      },
      "source": [
        "!tar -xvf /content/drive/My\\ Drive/DATASPARTAN/PROYECTOS/AI-DOCUMENTS/SEGMENTATION/DSFigureDataset.tar.gz -C {dataset_folderpath}\n",
        "\n",
        "clear_output()\n",
        "\n",
        "!ls {dataset_folderpath}"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raw  setup.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xcmd3sFYkvZZ",
        "colab_type": "text"
      },
      "source": [
        "### Split `train`, `val` and `test` dataset\n",
        "\n",
        "The `zip` contains a script to generate the ml dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2CwmJAIk04f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9457d98b-0ae2-445b-84b6-46768454b685"
      },
      "source": [
        "% cd {dataset_folderpath}\n",
        "!python setup.py"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/input\n",
            "Number of classes : 20\n",
            "['LineGraph', 'BubbleChart', 'BoxPlot', 'PersonPhoto', 'VennDiagram', 'NetworkDiagram', 'GeneralPhoto', 'ParetoChart', 'ScatterGraph', 'Table', 'GeneralFigure', 'TreeDiagram', 'Signatures', 'Map', 'RadarPlot', 'AreaGraph', 'PieChart', 'FlowChart', 'HorizontalBarGraph', 'VerticalBarGraph']\n",
            "LineGraph: \n",
            "   > ntrain : 91\n",
            "   > nval : 37\n",
            "   > ntest : 2\n",
            "\n",
            "BubbleChart: \n",
            "   > ntrain : 65\n",
            "   > nval : 28\n",
            "   > ntest : 1\n",
            "\n",
            "BoxPlot: \n",
            "   > ntrain : 109\n",
            "   > nval : 46\n",
            "   > ntest : 2\n",
            "\n",
            "PersonPhoto: \n",
            "   > ntrain : 76\n",
            "   > nval : 31\n",
            "   > ntest : 2\n",
            "\n",
            "VennDiagram: \n",
            "   > ntrain : 100\n",
            "   > nval : 42\n",
            "   > ntest : 2\n",
            "\n",
            "NetworkDiagram: \n",
            "   > ntrain : 67\n",
            "   > nval : 28\n",
            "   > ntest : 1\n",
            "\n",
            "GeneralPhoto: \n",
            "   > ntrain : 42\n",
            "   > nval : 18\n",
            "   > ntest : 1\n",
            "\n",
            "ParetoChart: \n",
            "   > ntrain : 97\n",
            "   > nval : 40\n",
            "   > ntest : 2\n",
            "\n",
            "ScatterGraph: \n",
            "   > ntrain : 70\n",
            "   > nval : 29\n",
            "   > ntest : 1\n",
            "\n",
            "Table: \n",
            "   > ntrain : 75\n",
            "   > nval : 31\n",
            "   > ntest : 2\n",
            "\n",
            "GeneralFigure: \n",
            "   > ntrain : 111\n",
            "   > nval : 46\n",
            "   > ntest : 2\n",
            "\n",
            "TreeDiagram: \n",
            "   > ntrain : 108\n",
            "   > nval : 45\n",
            "   > ntest : 2\n",
            "\n",
            "Signatures: \n",
            "   > ntrain : 72\n",
            "   > nval : 30\n",
            "   > ntest : 2\n",
            "\n",
            "Map: \n",
            "   > ntrain : 116\n",
            "   > nval : 48\n",
            "   > ntest : 2\n",
            "\n",
            "RadarPlot: \n",
            "   > ntrain : 72\n",
            "   > nval : 30\n",
            "   > ntest : 2\n",
            "\n",
            "AreaGraph: \n",
            "   > ntrain : 121\n",
            "   > nval : 51\n",
            "   > ntest : 2\n",
            "\n",
            "PieChart: \n",
            "   > ntrain : 137\n",
            "   > nval : 57\n",
            "   > ntest : 2\n",
            "\n",
            "FlowChart: \n",
            "   > ntrain : 77\n",
            "   > nval : 31\n",
            "   > ntest : 2\n",
            "\n",
            "HorizontalBarGraph: \n",
            "   > ntrain : 112\n",
            "   > nval : 46\n",
            "   > ntest : 2\n",
            "\n",
            "VerticalBarGraph: \n",
            "   > ntrain : 251\n",
            "   > nval : 105\n",
            "   > ntest : 4\n",
            "\n",
            "Num total of train examples : 1969\n",
            "Num total of val examples : 819\n",
            "Num total of test examples : 38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3D6HWBErT2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_folder = \"/content/input/dataset\"\n",
        "\n",
        "trn_folder = os.path.join(input_folder,\"train\")\n",
        "val_folder = os.path.join(input_folder,\"val\")\n",
        "test_folder = os.path.join(input_folder,\"test\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p7pa85unzhv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "08b3ed7f-dba5-4a83-d4b6-0c91b6acb9ed"
      },
      "source": [
        "classes = [name for name in os.listdir(trn_folder) \n",
        "      if os.path.isdir(os.path.join(trn_folder,name))]\n",
        "print(f\"Number of classes : {len(classes)}\")\n",
        "print(classes)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of classes : 20\n",
            "['LineGraph', 'BubbleChart', 'BoxPlot', 'PersonPhoto', 'VennDiagram', 'NetworkDiagram', 'GeneralPhoto', 'ParetoChart', 'ScatterGraph', 'Table', 'GeneralFigure', 'TreeDiagram', 'Signatures', 'Map', 'RadarPlot', 'AreaGraph', 'PieChart', 'FlowChart', 'HorizontalBarGraph', 'VerticalBarGraph']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM7jPqRuxoHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Output of script\n",
        "total_test=38"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx71JKlq15P4",
        "colab_type": "text"
      },
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0idoKJN2Raa",
        "colab_type": "text"
      },
      "source": [
        "Train and Val files are distributed in each folder with subfolders by class:\n",
        "\n",
        "```\n",
        " folder\\\n",
        "    cls1\\\n",
        "        image.png\n",
        "        image2.jpeg\n",
        "        image3.png\n",
        "        ...\n",
        "    cls2\\\n",
        "        imageA.jpeg\n",
        "        imageB.jpg\n",
        "        imageC.png\n",
        "        ...\n",
        "    ...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3bHIRxaw4ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_HEIGHT = 512\n",
        "IMG_WIDTH = 512\n",
        "batch_size = 2"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW2_b51Y_DPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create dataloaders\n",
        "tfms = transforms.Compose([transforms.Resize((IMG_HEIGHT,IMG_WIDTH)), \n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize([0.458, 0.456, 0.406],\n",
        "                                                [0.229, 0.224, 0.225])])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO2sgRdp_pOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = ImageFolder(trn_folder, tfms)\n",
        "valid = ImageFolder(val_folder, tfms)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL9iZcxr_pLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_loader = DataLoader(train, batch_size=batch_size, num_workers=4)\n",
        "valid_data_loader = DataLoader(valid, batch_size=batch_size, num_workers=4)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro_S8FAB_-lH",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CaSAXI6_pIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.ConvLayer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 8, 3), # inp (3, 512, 512)\n",
        "            nn.Conv2d(8, 16, 3),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.ReLU() # op (16, 256, 256)\n",
        "        )\n",
        "        self.ConvLayer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, 5), # inp (16, 256, 256)\n",
        "            nn.Conv2d(32, 32, 3),\n",
        "            nn.MaxPool2d(4),\n",
        "            nn.ReLU() # op (32, 64, 64)\n",
        "        )\n",
        "        self.ConvLayer3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3), # inp (32, 64, 64)\n",
        "            nn.Conv2d(64, 64, 5),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.ReLU() # op (64, 32, 32)\n",
        "        )\n",
        "        self.ConvLayer4 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 5), # inp (64, 32, 32)\n",
        "            nn.Conv2d(128, 128, 3),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.ReLU() # op (128, 16, 16)\n",
        "        )\n",
        "        self.Lin1 = nn.Linear(15488, 20) # 15488 = 512x512 : Resize all images to 512x512  # Len(classes) = 20\n",
        "        self.Lin2 = nn.Linear(1500, 150)\n",
        "        self.Lin3 = nn.Linear(150, 20) # Len(classes) = 20\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.ConvLayer1(x)\n",
        "        x = self.ConvLayer2(x)\n",
        "        x = self.ConvLayer3(x)\n",
        "        x = self.ConvLayer4(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.Lin1(x)\n",
        "       \n",
        "        \n",
        "        return F.log_softmax(x, dim = 1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaBTfHRE_5rm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Net()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04GPj_pJ_5oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "else:\n",
        "  print(\"GPU is not available. The trainning process could be really slow.\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iPF1h6s_5lB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.5)\n",
        "for epoch in tqdm(range(50)):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_data_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        \n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        # if i % 10 == 0:    # print every 10 mini-batches\n",
        "        #     print('[%d, %5d] loss: %.3f' %\n",
        "        #           (epoch + 1, i + 1, running_loss / 2000))\n",
        "        #     running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJcu2_ZyS24i",
        "colab_type": "text"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fehjiYt_5hE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "325dcfef-1e78-4a6a-c303-931b82972452"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in valid_data_loader:\n",
        "        images, labels = data\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 12 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUMTBhNqSsys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}